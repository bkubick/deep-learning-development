{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2caf223",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks & Computer Vision\n",
    "\n",
    "Computer vision offers a way to take real world images, and computationally analyze to predict and find patterns within visual data. For instance, the camera of a Self-Driving car.\n",
    "\n",
    "Why can't this be done using normal Feed-Forward Neural Networks? Simple, the first step in analyzing an image with Feed Forward Neural Nets, you need to flatten the image to a single vector. For instance, a 28 x 28 pixel image flattens to a vector of length, 784. This is an extremely small image, and the inputs is of length 784. This is problematic with larger images because for the deep neural network to analyze, because there will be an extremely high number of weights to populate, and makes identifying patterns an extremly complex task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6c52e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79031e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f984ec",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d174f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_image_directory(data_directory: pathlib.Path):\n",
    "    # Lets look at the number of files in the test and train sets\n",
    "    # TODO: Move this to a nice function\n",
    "    for dirpath, dirnames, filenames in os.walk(data_directory):\n",
    "        images = [file for file in filenames if file.endswith('jpg') or file.endswith('jpeg') or file.endswith('png')]\n",
    "        if images:\n",
    "            print(f'Directory: {dirpath} Total Images: {len(images)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a236de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classnames_from_directory(data_directory: pathlib.Path):\n",
    "    all_class_names = [\n",
    "        item.name for item in data_directory.iterdir() if item.is_dir() and not item.name.startswith('.')\n",
    "    ]\n",
    "    class_names = np.array(sorted(all_class_names))\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_random_image(target_dir: str, target_class: str):\n",
    "    target_folder = f'{target_dir}/{target_class}'\n",
    "\n",
    "    random_image = random.sample(os.listdir(target_folder), 1)\n",
    "    img = mpimg.imread(target_folder + '/' + random_image[0])\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title(target_class)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    print(f'{target_class.capitalize()} - Image Shape: {img.shape}')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4e3826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_image_from_batch(images, labels, index = None):\n",
    "    if index is None:\n",
    "        index = random.randint(0,len(images)-1)\n",
    "    plt.figure()\n",
    "    plt.imshow(images[index])\n",
    "    plt.title(labels[index])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38bdb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prep_image(filename, img_shape=224):\n",
    "    \"\"\" Reads and preprocesses a custom image.\"\"\"\n",
    "    img = tf.io.read_file(filename)\n",
    "    \n",
    "    # Decode file into a tensor\n",
    "    img = tf.image.decode_image(img)\n",
    "    \n",
    "    # Resize image\n",
    "    img = tf.image.resize(img, size=(img_shape, img_shape))\n",
    "    \n",
    "    # Normalize the image\n",
    "    img = img / 255.\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_class(model, filename, class_names):\n",
    "    # Loading and prepping the image\n",
    "    prepped_img = load_and_prep_image(filename)\n",
    "    \n",
    "    # Predicting the image\n",
    "    prediction = model.predict(tf.expand_dims(prepped_img, axis=0))\n",
    "    \n",
    "    # Need to check for binary vs multiclass\n",
    "    if len(prediction[0]) > 1:\n",
    "        class_name = class_names[tf.argmax(prediction[0])]\n",
    "    else:\n",
    "        class_name_index = int(tf.round(prediction))\n",
    "        class_name = class_names[class_name_index]\n",
    "    \n",
    "    # Plotting the image\n",
    "    plt.figure()\n",
    "    plt.imshow(prepped_img)\n",
    "    plt.title(f'Image: {class_name.capitalize()} ({str(prediction[0][0]*100)[:4]}% Confident)')\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a00b6",
   "metadata": {},
   "source": [
    "## Download & Analyze Dataset\n",
    "\n",
    "The dataset used is the Food 101 dataset commonly used to to explore Computer Vision. For simplicity of getting started with Computer Vision, I am only going to be looking at two image classes to work quickly with a smaller dataset before applying learnings to the larger dataset.\n",
    "\n",
    "* https://www.kaggle.com/datasets/dansbecker/food-101 (original kaggle page of dataset)\n",
    "* https://github.com/mrdbourke/tensorflow-deep-learning/ (getting the modified dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af386bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dataset location\n",
    "data_directory = pathlib.Path('./data/food-101/pizza_steak')\n",
    "test_directory = data_directory / 'test'\n",
    "train_directory = data_directory / 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb36e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at the number of files in the test and train sets\n",
    "# TODO: Move this to a nice function\n",
    "for dirpath, dirnames, filenames in os.walk(str(data_directory)):\n",
    "    images = [file for file in filenames if file.endswith('jpg') or file.endswith('jpeg') or file.endswith('png')]\n",
    "    if images:\n",
    "        print(f'Directory: {dirpath} Total Images: {len(images)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce65857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Class names programatically\n",
    "class_names = np.array(sorted([item.name for item in train_directory.iterdir() if item.is_dir() and not item.name.startswith('.')]))\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800787f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View a random img from training dataset\n",
    "pizza_img = view_random_image(target_dir=str(train_directory), target_class=class_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb747713",
   "metadata": {},
   "outputs": [],
   "source": [
    "steak_img = view_random_image(target_dir=str(train_directory), target_class=class_names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b1796c",
   "metadata": {},
   "source": [
    "## End-to-End Example\n",
    "\n",
    "1. Need to load our images.\n",
    "2. Need to normalize the images\n",
    "3. Need to build. a CNN to find patterns in our images.\n",
    "4. Need to compile our CNN.\n",
    "5. Fit the CNN to training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731854a0",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774d26bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Preprocessing the data (Normalize all pixel values)\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "valid_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 2. Import data from directories and turn it into batches\n",
    "train_data = train_data_gen.flow_from_directory(\n",
    "    directory=str(train_directory),\n",
    "    batch_size=32,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='binary',\n",
    "    seed=42)\n",
    "\n",
    "valid_data = valid_data_gen.flow_from_directory(\n",
    "    directory=str(test_directory),\n",
    "    batch_size=32,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='binary',\n",
    "    seed=42)\n",
    "\n",
    "# 3. Build the CNN Model\n",
    "model_1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=10,\n",
    "                           kernel_size=3,\n",
    "                           activation='relu',\n",
    "                           input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.Conv2D(10, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2,\n",
    "                              padding='valid'),\n",
    "    tf.keras.layers.Conv2D(10, 3, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(10, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 4. Compile CNN Model\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "                metrics='accuracy')\n",
    "\n",
    "# 5. Fit the CNN Model\n",
    "history_1 = model_1.fit(train_data, epochs=5, steps_per_epoch=len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55023b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_history(history_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b663cb",
   "metadata": {},
   "source": [
    "### Feed Forward Neural Network Model (For Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting random seed for comparison\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create Model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(224, 224, 3)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 3. Fit Model\n",
    "model_2.fit(train_data,\n",
    "            epochs=5,\n",
    "            steps_per_epoch=len(train_data),\n",
    "            validation_data=valid_data,\n",
    "            validation_steps=len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a54d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at some details of model_2\n",
    "# There are ~602,000 trainable parameters here (20X more parameters than model 1).\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf5cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if we can make a better feed forward model\n",
    "# Setting random seed for comparison\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create Model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(224, 224, 3)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "model_3.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 3. Fit Model\n",
    "model_3.fit(train_data,\n",
    "            epochs=5,\n",
    "            steps_per_epoch=len(train_data),\n",
    "            validation_data=valid_data,\n",
    "            validation_steps=len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fcba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at model 3 structure\n",
    "# ~15 million trainable parameters (500X number of trainable parameters compared to the CNN)\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b4d58f",
   "metadata": {},
   "source": [
    "# Re-looking at Convolutional Neural Network Steps\n",
    "\n",
    "Now that I have done a simple example of a CNN, and compared it against the feed forward neural network, I am going to take a step back and analyze the actual steps that goes into building out a CNN.\n",
    "\n",
    "## Binary Classification (Breaking it Down)\n",
    "\n",
    "1. Become one with the data\n",
    "2. Preprocess the data (scaled/normalized)\n",
    "3. Created model (started with a simple baseline)\n",
    "4. Fit the Model\n",
    "5. Evaluate the Model\n",
    "6. Adjust and improve the Model (Beat the baseline)\n",
    "7. Repeat until optimal/satisfied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8db1ab",
   "metadata": {},
   "source": [
    "## 0. Gathering the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd6539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dataset location\n",
    "data_directory = pathlib.Path('./data/food-101/pizza_steak')\n",
    "test_directory = data_directory / 'test'\n",
    "train_directory = data_directory / 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de6543c",
   "metadata": {},
   "source": [
    "## 1. Analyzing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0e15f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "steak_img = view_random_image(target_dir=str(train_directory), target_class=class_names[1])\n",
    "plt.subplot(1, 2, 2)\n",
    "pizza_img = view_random_image(target_dir=str(train_directory), target_class=class_names[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26667977",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Data\n",
    "\n",
    "Preparing data for the model (split data, normalize data, batch data, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f7352",
   "metadata": {},
   "source": [
    "### 2.1 Batch Data\n",
    "\n",
    "The next step is to turn out data into **batches**. A batch is a small subset of data. Rather than look at all ~10,000 images at one time, a model might only look at 32 at a time. It does this for a couple of reasons:\n",
    "\n",
    "1. 10,000 images (or more) might not fit into the memory of the processor.\n",
    "2. Trying to learn the patterns in 10,000 images in one hit could result in a poorly learned model.\n",
    "\n",
    "**NOTE** A batch size of 32 is a commonly used batch size for neural networks, and has been tested and found that it is a good batch size for many scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train and test data generators\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_data_gen.flow_from_directory(\n",
    "    directory=str(train_directory),\n",
    "    batch_size=32,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='binary',\n",
    "    seed=42)\n",
    "\n",
    "test_data = valid_data_gen.flow_from_directory(\n",
    "    directory=str(test_directory),\n",
    "    batch_size=32,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='binary',\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939b700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample of a train data batch\n",
    "images, labels = train_data.next()\n",
    "len(images), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the shape of each image, and verify that it has been normalized\n",
    "images[0].shape, images[0].max(), images[0].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc588672",
   "metadata": {},
   "source": [
    "## 3. Create, Compile, Fit & Evaluate Model\n",
    "\n",
    "Starting with a Baseline model. A Baseline mode is a relatively simple model or existing result that you setup when beginning a machine learning experiment, and is used as a baseline when trying to improve your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cb2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the Model Creation simpler\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3deea",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d091986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create Model\n",
    "baseline_model = Sequential([\n",
    "    Conv2D(filters=10,\n",
    "           kernel_size=3,\n",
    "           strides=1,\n",
    "           padding='valid',\n",
    "           activation='relu',\n",
    "           input_shape=(224, 224, 3),\n",
    "           name='InputLayer'),\n",
    "    Conv2D(10, 3, activation='relu'),\n",
    "    Conv2D(10, 3, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid', name='OutputLayer')\n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "baseline_model.compile(loss='binary_crossentropy',\n",
    "                       optimizer=Adam(),\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# 3. Fit Model\n",
    "# NOTE: train_data is a combination of X and y, so don't need to send both\n",
    "# NOTE: We don't have a validation dataset, so going to use the test set\n",
    "baseline_history = baseline_model.fit(train_data,\n",
    "                                      epochs=5,\n",
    "                                      steps_per_epoch=len(train_data),\n",
    "                                      validation_data=test_data,\n",
    "                                      validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d93a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b6d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_history(baseline_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f789dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_history(baseline_history, metric='loss')\n",
    "utils.plot.plot_history(baseline_history, metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87676a02",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "\n",
    "When a models's validation loss starts to increase, it's likely that the model is overfitting the training dataset This means it's learning the patterns in the training set too well and thus the model's ability to generalize unseen data will be diminished."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c08da",
   "metadata": {},
   "source": [
    "### Model-1: Adust Model to Combat Overfitting\n",
    "\n",
    "Fitting a machine learning model comes in 3 steps:\n",
    "\n",
    "0. Create a baseline model to compare models against.\n",
    "1. Beat the baseline by overfitting a larger model.\n",
    "2. Reduce overfitting,\n",
    "\n",
    "Ways to induce overfitting:\n",
    "\n",
    "1. Increase the number of conv layers.\n",
    "2. Increase the number of conv filters.\n",
    "3. Add another dense layer to the output of our flattened layer.\n",
    "\n",
    "\n",
    "Reduce overfitting:\n",
    "\n",
    "1. Add data augmentation.\n",
    "2. Add regularization (MaxPool2D).\n",
    "3. Add more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7842e6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create Model\n",
    "model_1 = Sequential([\n",
    "    Conv2D(filters=10,\n",
    "           kernel_size=3,\n",
    "           strides=1,\n",
    "           padding='valid',\n",
    "           activation='relu',\n",
    "           input_shape=(224, 224, 3),\n",
    "           name='InputLayer'),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Conv2D(10, 3, activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(10, 3, activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid', name='OutputLayer')\n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "                optimizer=Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 3. Fit Model\n",
    "# NOTE: train_data is a combination of X and y, so don't need to send both\n",
    "# NOTE: We don't have a validation dataset, so going to use the test set\n",
    "model_1_history = model_1.fit(train_data,\n",
    "                              epochs=5,\n",
    "                              steps_per_epoch=len(train_data),\n",
    "                              validation_data=test_data,\n",
    "                              validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c77af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_history(model_1_history, metric='loss')\n",
    "utils.plot.plot_history(model_1_history, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e114174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7226ef09",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "\n",
    "After implementing pooling into the CNN, the training data set and the validation (testing in our case) data set followed a similar trajectory. This is what we want to see in our models which limits overfitting.\n",
    "\n",
    "NOTE: Reducing overfitting is also know as regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb50df9a",
   "metadata": {},
   "source": [
    "## Model-2: Adjust Overfitting using Data Augmentation\n",
    "\n",
    "Data augmentation is the process of altering our training data, leading it to have more diversity and in turn allowing ormodels to learn more generalizable (hopefully) patterns. Alterming might mean adjusting the rotation of an image, flipping it, cropping it, etc.\n",
    "\n",
    "**NOTE** Data augmentation is usually only performed on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08928ef6",
   "metadata": {},
   "source": [
    "### Resetting Up the ImageDataGenerator & Image Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60640832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ImageDataGenerator training instance with Data Augmentation\n",
    "train_data_gen_augmented = ImageDataGenerator(rescale=1./255,\n",
    "                                             rotation_range=0.2,\n",
    "                                             shear_range=0.2,\n",
    "                                             zoom_range=0.2,\n",
    "                                             width_shift_range=0.2,\n",
    "                                             height_shift_range=0.3,\n",
    "                                             horizontal_flip=True)\n",
    "\n",
    "# Create ImageDataGenerator training instance without DataAugmentation\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Creating the datasets for training and test sets\n",
    "train_data_augmented = train_data_gen_augmented.flow_from_directory(\n",
    "    directory=str(train_directory),\n",
    "    batch_size=32,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "train_data = train_data_gen.flow_from_directory(\n",
    "    directory=str(train_directory),\n",
    "    batch_size=32,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='binary',\n",
    "    shuffle=False)\n",
    "\n",
    "test_data = test_data_gen.flow_from_directory(\n",
    "    directory=str(test_directory),\n",
    "    batch_size=32,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b613c2a",
   "metadata": {},
   "source": [
    "### Visualizing the Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d8b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = train_data.next()\n",
    "augmented_images, augmented_labels = train_data_augmented.next()\n",
    "\n",
    "random_index = random.randint(0, len(images)-1)\n",
    "\n",
    "view_image_from_batch(images, labels, random_index)\n",
    "view_image_from_batch(augmented_images, augmented_labels, random_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8adbc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create Model\n",
    "model_2 = Sequential([\n",
    "    Conv2D(filters=10,\n",
    "           kernel_size=3,\n",
    "           strides=1,\n",
    "           padding='valid',\n",
    "           activation='relu',\n",
    "           input_shape=(224, 224, 3),\n",
    "           name='InputLayer'),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Conv2D(10, 3, activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(10, 3, activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid', name='OutputLayer')\n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "model_2.compile(loss='binary_crossentropy',\n",
    "                optimizer=Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 3. Fit Model\n",
    "# NOTE: train_data is a combination of X and y, so don't need to send both\n",
    "# NOTE: We don't have a validation dataset, so going to use the test set\n",
    "model_2_history = model_2.fit(train_data_augmented,\n",
    "                              epochs=5,\n",
    "                              steps_per_epoch=len(train_data_augmented),\n",
    "                              validation_data=test_data,\n",
    "                              validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4cb722",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_history(model_2_history, metric='loss')\n",
    "utils.plot.plot_history(model_2_history, metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba49567",
   "metadata": {},
   "source": [
    "## Model-3: Augmentation w/ Shuffled Data\n",
    "\n",
    "In model 2, I didn't shuffle the data so I could see exactly what the augmentation does against data. Going to do the same thing as model-2, but turn on shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d49cd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ImageDataGenerator training instance with Data Augmentation\n",
    "train_data_gen_augmented = ImageDataGenerator(rescale=1./255,\n",
    "                                             rotation_range=0.2,\n",
    "                                             shear_range=0.2,\n",
    "                                             zoom_range=0.2,\n",
    "                                             width_shift_range=0.2,\n",
    "                                             height_shift_range=0.3,\n",
    "                                             horizontal_flip=True)\n",
    "\n",
    "# Create ImageDataGenerator training instance without DataAugmentation\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Creating the datasets for training and test sets\n",
    "train_data_augmented = train_data_gen_augmented.flow_from_directory(\n",
    "    directory=str(train_directory),\n",
    "    batch_size=32,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='binary',\n",
    "    shuffle=True)\n",
    "\n",
    "test_data = test_data_gen.flow_from_directory(\n",
    "    directory=str(test_directory),\n",
    "    batch_size=32,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5428cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create Model\n",
    "model_3 = Sequential([\n",
    "    Conv2D(filters=10,\n",
    "           kernel_size=3,\n",
    "           strides=1,\n",
    "           padding='valid',\n",
    "           activation='relu',\n",
    "           input_shape=(224, 224, 3),\n",
    "           name='InputLayer'),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Conv2D(10, 3, activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(10, 3, activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid', name='OutputLayer')\n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "model_3.compile(loss='binary_crossentropy',\n",
    "                optimizer=Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 3. Fit Model\n",
    "# NOTE: train_data is a combination of X and y, so don't need to send both\n",
    "# NOTE: We don't have a validation dataset, so going to use the test set\n",
    "model_3_history = model_3.fit(train_data_augmented,\n",
    "                              epochs=5,\n",
    "                              steps_per_epoch=len(train_data_augmented),\n",
    "                              validation_data=test_data,\n",
    "                              validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32b97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_history(model_3_history, metric='loss')\n",
    "utils.plot.plot_history(model_3_history, metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fd750a",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "Just turning on shuffling for the training data sifnificantly increased accuracy from model 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced38d00",
   "metadata": {},
   "source": [
    "## Model 4: Improve Accuracy by Increase Filters in Each Layer\n",
    "\n",
    "Since we've already beaten our baseline, there are a few things to try to improve the model:\n",
    "\n",
    "1. Increate number of model layers.\n",
    "2. Increate filters in each layer.\n",
    "3. Train for longer..\n",
    "4. Find ideal learning rate.\n",
    "5. More data!\n",
    "6. Use transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd1871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create Model\n",
    "model_4 = Sequential([\n",
    "    Conv2D(filters=20,\n",
    "           kernel_size=3,\n",
    "           strides=1,\n",
    "           padding='valid',\n",
    "           activation='relu',\n",
    "           input_shape=(224, 224, 3),\n",
    "           name='InputLayer'),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Conv2D(20, 3, activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(20, 3, activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid', name='OutputLayer')\n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "model_4.compile(loss='binary_crossentropy',\n",
    "                optimizer=Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 3. Fit Model\n",
    "# NOTE: train_data is a combination of X and y, so don't need to send both\n",
    "# NOTE: We don't have a validation dataset, so going to use the test set\n",
    "model_4_history = model_4.fit(train_data_augmented,\n",
    "                              epochs=5,\n",
    "                              steps_per_epoch=len(train_data_augmented),\n",
    "                              validation_data=test_data,\n",
    "                              validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c9615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_history(model_4_history, metric='loss')\n",
    "utils.plot.plot_history(model_4_history, metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b6576",
   "metadata": {},
   "source": [
    "## Model 5: Increase Accuracy by Training for Longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c644039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create Model\n",
    "model_5 = Sequential([\n",
    "    Conv2D(filters=20,\n",
    "           kernel_size=3,\n",
    "           strides=1,\n",
    "           padding='valid',\n",
    "           activation='relu',\n",
    "           input_shape=(224, 224, 3),\n",
    "           name='InputLayer'),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Conv2D(20, 3, activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(20, 3, activation='relu'),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid', name='OutputLayer')\n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "model_5.compile(loss='binary_crossentropy',\n",
    "                optimizer=Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 3. Fit Model\n",
    "# NOTE: train_data is a combination of X and y, so don't need to send both\n",
    "# NOTE: We don't have a validation dataset, so going to use the test set\n",
    "model_5_history = model_5.fit(train_data_augmented,\n",
    "                              epochs=10,\n",
    "                              steps_per_epoch=len(train_data_augmented),\n",
    "                              validation_data=test_data,\n",
    "                              validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6708e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_history(model_5_history, metric='loss')\n",
    "utils.plot.plot_history(model_5_history, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b0464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Image location\n",
    "test_image_directory = pathlib.Path('./data/food-101/model_testing')\n",
    "steak_filename = test_image_directory / 'steak' / 'steak-and-eggs-2-2.jpeg'\n",
    "steak_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568919a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "steak = mpimg.imread(steak_filename)\n",
    "plt.imshow(steak)\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b5263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "steak.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4a877c",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "\n",
    "When you train a neural network and you want to make a preduction with it on you own custom data, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805173e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_predicted_class(model_4, str(steak_filename), class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed917a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d443741",
   "metadata": {},
   "source": [
    "# Multi-class Image Classification\n",
    "\n",
    "We've just been through a bunch of the steps below with binary classification. Now I am going to perform the following steps with a multi-class classification problem.\n",
    "\n",
    "1. Become one with the data\n",
    "2. Prepreocess the data.\n",
    "3. Create a model (start with baseline).\n",
    "4. Fit the model (overfit it to make sure it works).\n",
    "5. Evaluate the model\n",
    "6. Adjust hyperparameters to improve the model and reduce overfitting.\n",
    "7. Repeat until satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ea7896",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87285f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f132d6b",
   "metadata": {},
   "source": [
    "## Download & Analyze Dataset\n",
    "\n",
    "The dataset used is the Food 101 dataset commonly used to to explore Computer Vision. For simplicity of getting started with Computer Vision, I am only going to be looking at two image classes to work quickly with a smaller dataset before applying learnings to the larger dataset.\n",
    "\n",
    "* https://www.kaggle.com/datasets/dansbecker/food-101 (original kaggle page of dataset)\n",
    "* https://github.com/mrdbourke/tensorflow-deep-learning/ (getting the modified dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47216da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dataset location\n",
    "data_directory = pathlib.Path('./data/food-101/10_food_classes_all_data')\n",
    "test_directory = data_directory / 'test'\n",
    "train_directory = data_directory / 'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc8da52",
   "metadata": {},
   "source": [
    "## 1. Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9bfab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_image_directory(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34415ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the subdirectories\n",
    "class_names = get_classnames_from_directory(train_directory)\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ce006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at some images\n",
    "img = view_random_image(target_dir=train_directory, target_class=random.choice(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36210f4",
   "metadata": {},
   "source": [
    "## 2. Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712030d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling values\n",
    "scale = 1. / 255\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "\n",
    "# Creating data generator\n",
    "train_data_gen = ImageDataGenerator(rescale=scale)\n",
    "test_data_gen = ImageDataGenerator(rescale=scale)\n",
    "\n",
    "# Loading data in batches\n",
    "train_data = train_data_gen.flow_from_directory(str(train_directory),\n",
    "                                                target_size=(img_size, img_size),\n",
    "                                                batch_size=batch_size,\n",
    "                                                class_mode='categorical')\n",
    "\n",
    "test_data = test_data_gen.flow_from_directory(str(test_directory),\n",
    "                                              target_size=(img_size, img_size),\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6199e2af",
   "metadata": {},
   "source": [
    "## 3. Create the Baseline Model\n",
    "\n",
    "We've been takling a lot wabout the CNN explainer website. They've been using 10 classes as well, so lets start out with creating our baseline model using the same architecture they use.\n",
    "\n",
    "* https://poloclub.github.io/cnn-explainer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310faac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create Model (same as in CNN explainer)\n",
    "baseline_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=10,\n",
    "                           kernel_size=3,\n",
    "                           strides=1,\n",
    "                           padding='valid',\n",
    "                           activation='relu',\n",
    "                           input_shape=(img_size, img_size, 3),\n",
    "                           name='InputLayer'),\n",
    "    tf.keras.layers.Conv2D(filters=10, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),\n",
    "    tf.keras.layers.Conv2D(filters=10, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=10, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name='OutputLayer')\n",
    "    \n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "baseline_model.compile(loss='categorical_crossentropy',\n",
    "                       optimizer=tf.keras.optimizers.Adam(),\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# 3. Fit Model\n",
    "baseline_history = baseline_model.fit(train_data,\n",
    "                                      epochs=5,\n",
    "                                      steps_per_epoch=len(train_data),\n",
    "                                      validation_data=test_data,\n",
    "                                      validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef31d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deecb7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_history(baseline_history, metric='loss')\n",
    "utils.plot.plot_history(baseline_history, metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98768b79",
   "metadata": {},
   "source": [
    "### Findings\n",
    "\n",
    "From the loss curves, it the validation loss starts to increase when the training loss decreases, indicating that the model is overfitting. Next steps to adjust overfitting is to introduce data augmentation, regularization, etc.\n",
    "\n",
    "Ways of adjusting the model for overfitting:\n",
    "\n",
    "1. Get more data. This allows for more opportunity to learn diverse patterns.\n",
    "2. Simplify the model. Remove layers, filters, etc.\n",
    "3. Data Augmentation. Data augmentation manipulates the training data in such a way to add more diversity to it without altering the original data.\n",
    "4. Transfer Learning: Transf er learning leverages the patterens another model has similar data that has been fitted for, and we can use those patterns on our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a48d3fc",
   "metadata": {},
   "source": [
    "## Model-1: Adjust for Overfitting by Simplifying Model (Removing Layers)\n",
    "\n",
    "Cutting out the two Conv2D layers before the MaxPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82dbb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create Model (same as in CNN explainer)\n",
    "model_1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=10,\n",
    "                           kernel_size=3,\n",
    "                           strides=1,\n",
    "                           padding='valid',\n",
    "                           activation='relu',\n",
    "                           input_shape=(img_size, img_size, 3),\n",
    "                           name='InputLayer'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),\n",
    "    tf.keras.layers.Conv2D(filters=10, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name='OutputLayer')\n",
    "    \n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "                       optimizer=tf.keras.optimizers.Adam(),\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "# 3. Fit Model\n",
    "model_1_history = model_1.fit(train_data,\n",
    "                                      epochs=5,\n",
    "                                      steps_per_epoch=len(train_data),\n",
    "                                      validation_data=test_data,\n",
    "                                      validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cfd92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_history(model_1_history, metric='loss')\n",
    "utils.plot.plot_history(model_1_history, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acf2eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bb4ae",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "\n",
    "From the loss curves, the accuracy went down and overfitting remained. Next step is to adjust the overfitting of the baseline model with data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b499fc9",
   "metadata": {},
   "source": [
    "## Model-2: Addressing Overfitting Using Data Augmentation\n",
    "\n",
    "Trying to reduce overitting with data augmentation. Ideally, we want to:\n",
    "* Reduce overfitting\n",
    "* Increase validation accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e352d4c",
   "metadata": {},
   "source": [
    "##### Step-0: Loading, Preprocessing, and Augmenting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e92d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling values\n",
    "scale = 1. / 255\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "\n",
    "# Creating data generator\n",
    "train_data_augmented_gen = ImageDataGenerator(rescale=scale,\n",
    "                                    rotation_range=0.2,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True)\n",
    "test_data_gen = ImageDataGenerator(rescale=scale)\n",
    "\n",
    "# Loading data in batches\n",
    "train_data = train_data_augmented_gen.flow_from_directory(str(train_directory),\n",
    "                                                          target_size=(img_size, img_size),\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          class_mode='categorical')\n",
    "\n",
    "test_data = test_data_gen.flow_from_directory(str(test_directory),\n",
    "                                              target_size=(img_size, img_size),\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c087c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create Model (using clone model for quick)\n",
    "model_2 = tf.keras.models.clone_model(baseline_model)\n",
    "\n",
    "# 2. Compile Model\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 3. Fit Model\n",
    "model_2_history = model_2.fit(train_data,\n",
    "                              epochs=5,\n",
    "                              steps_per_epoch=len(train_data),\n",
    "                              validation_data=test_data,\n",
    "                              validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74506dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_history(model_2_history, metric='loss')\n",
    "utils.plot.plot_history(model_2_history, metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dbe523",
   "metadata": {},
   "source": [
    "#### Findings:\n",
    "\n",
    "The loss curve looks significantly better! The loss curves resemble each other much better, and are still increasing after epoch 5, so more epochs would likely result in a better accuracy. How else can we experiment to improve this accuracy?\n",
    "\n",
    "* Adjust model architecture\n",
    "* Adjust augmentation hyper parameters.\n",
    "* Train for longer\n",
    "* Adjust learning rate.\n",
    "* Try Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71a3705",
   "metadata": {},
   "source": [
    "### Lets Test our Model w/ New Custom Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa6ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Image location\n",
    "test_image_directory = pathlib.Path('./data/food-101/model_testing')\n",
    "steak_filename = test_image_directory / 'steak' / 'steak-and-eggs-2-2.jpeg'\n",
    "steak_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8cf2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "steak = mpimg.imread(steak_filename)\n",
    "plt.imshow(steak)\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf89e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_predicted_class(model_2, str(steak_filename), class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a606b2",
   "metadata": {},
   "source": [
    "## Save & Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a75448",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save('saved_trained_model_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa76ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the model saved and loads correctly\n",
    "loaded_model_2 = tf.keras.models.load_model('saved_trained_model_2')\n",
    "loaded_model_2.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c524f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.evaluate(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
