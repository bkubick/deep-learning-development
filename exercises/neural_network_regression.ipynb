{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c40ac04",
   "metadata": {},
   "source": [
    "# Introduction to Neural Networks with TensorFlow\n",
    "\n",
    "We are going to simplify regression problems by predicting a numerical variable based on some other combination of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c08038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Plotting the model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe1f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some sample data for regression\n",
    "X = tf.constant(np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0]))\n",
    "y = tf.constant(np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0]))  # y = x + 10\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb17e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af60558e",
   "metadata": {},
   "source": [
    "## Input and Output Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69238b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Tensor for house info\n",
    "house_info = tf.constant(['bedroom', 'bathroom', 'garage'])  # Input\n",
    "house_price = tf.constant([939700])  # Output\n",
    "\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d51603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figuring out input and output shape for X and y?\n",
    "# NOTE: This doesn't work, the input shape should be (1,) and output shape should be (1,)\n",
    "input_shape = X.shape\n",
    "output_shape = y.shape\n",
    "input_shape, output_shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a0f6e77",
   "metadata": {},
   "source": [
    "## Steps in Modeling with TensorFlow\n",
    "\n",
    "1. Creating a model: define the input and output layers, as well as the hidden layers of a deep learning model.\n",
    "2. Compiling a model: define the loss function (in other words, the function which tellls our model how wrong it is) and the optimizer (tells our model how to improve the patterns it's learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
    "3. Fitting a model: letting the model try to find patterns between X and y (features and labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278455dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seet\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72c589f0",
   "metadata": {},
   "source": [
    "### Trial-1\n",
    "Creating a simple model to iterate and improve upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b6ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Create a model using sequential api\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(1)  # This defines the output layer of shape 1\n",
    "])\n",
    "model.input_shape, model.output_shape, model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ccee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compiling the model\n",
    "# losses.mae is Mean Absolute Error\n",
    "# In short, this takes the average of the error between the prediction and the actual value\n",
    "loss_function = tf.keras.losses.mae\n",
    "\n",
    "# optimizers.SGD is Stochastic Gradient Descent\n",
    "# NOTE: Using optimizers.legacy.SGD due to optimizers.SGD being slower on M1 Mac\n",
    "optimizer = tf.keras.optimizers.legacy.SGD()\n",
    "\n",
    "model.compile(loss=loss_function,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f794da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fit the model\n",
    "model.fit(X, y, epochs=5)  # epochs is how many times the model runs through the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cbbdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing predictions of the model\n",
    "model.predict([17.0])  # This is pretty far off, so next steps are to improve the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fc742c6",
   "metadata": {},
   "source": [
    "### Improving the model\n",
    "\n",
    "We can improve our model by altering the steps we took to create a model.\n",
    "\n",
    "1. **Creating a Model**: We can add more layers, increase number of neurons in each hidden layer, change the activation function of each layer.\n",
    "2. **Compiling a Model**: We can change the loss function, use a different optimization function, or the learning rate of the optimization function.\n",
    "3. **Fitting a Model**: We can fit a model with more epochs (cycle through training data more times) or on more data (give more examples to learn from).\n",
    "\n",
    "**NOTE**: It is better to start with a smaller model, then impr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15e6963c",
   "metadata": {},
   "source": [
    "### Trial-2\n",
    "Only difference between Trial 1 and Trial 2 is I will increase the epochs (number of cycles trained through the training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bc4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuilding/Improving the Model\n",
    "\n",
    "# 1. Create a model using sequential api\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(1)  # This defines the output layer of shape 1\n",
    "])\n",
    "\n",
    "# 2. Compiling the model\n",
    "# losses.mae is Mean Absolute Error\n",
    "# In short, this takes the average of the error between the prediction and the actual value\n",
    "loss_function = tf.keras.losses.mae\n",
    "\n",
    "# optimizers.SGD is Stochastic Gradient Descent\n",
    "# NOTE: Using optimizers.legacy.SGD due to optimizers.SGD being slower on M1 Mac\n",
    "optimizer = tf.keras.optimizers.legacy.SGD()\n",
    "\n",
    "model.compile(loss=loss_function,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['mae'])\n",
    "\n",
    "# 3. Fit the model (training for 100 epochs instead of 5)\n",
    "model.fit(X, y, epochs=100)  # epochs is how many times the model runs through the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96871961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing predictions of the model\n",
    "model.predict([17.0])  # This is pretty far off, so next steps are to improve the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fbc1cce",
   "metadata": {},
   "source": [
    "### Trial-3\n",
    "Keeping epochs the same as Trial-2, but adding a hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f943a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuilding/Improving the Model\n",
    "\n",
    "# 1. Create a model using sequential api\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(100, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compiling the Model\n",
    "loss_function = tf.keras.losses.mae\n",
    "optimizer = tf.keras.optimizers.legacy.SGD()\n",
    "\n",
    "model.compile(loss=loss_function, optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "# 3. Fit the Model\n",
    "model.fit(X, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c36f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing predictions of the model (Actual value should be 27)\n",
    "model.predict([17.0])  # Weird, this value prediction is not even close to the value, even though the mae is lower"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82730e92",
   "metadata": {},
   "source": [
    "### Trial-4\n",
    "Keeping epochs the same as Trial-2 and hidden layers from Trial-3, but changing the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ff122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuilding/Improving the Model\n",
    "\n",
    "# 1. Create a model using sequential api\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(100, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compiling the Model\n",
    "loss_function = tf.keras.losses.mae\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(lr=0.01)\n",
    "\n",
    "model.compile(loss=loss_function, optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "# 3. Fit the Model\n",
    "model.fit(X, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c6d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing predictions of the model (Actual value should be 27)\n",
    "model.predict([17.0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da88ade8",
   "metadata": {},
   "source": [
    "## Evaluating a Model\n",
    "\n",
    "In practive, a typical workflow you'll go through consists of the following:\n",
    "\n",
    "create a model -> fit it -> evaluat it  -> tweak it -> repeat....\n",
    "\n",
    "**Most Important to Eavluating**\n",
    "Most important step of eavluating a model is to Visualize. It's a good idea to visualize:\n",
    "* The data: what data are we working with? What does it look like?\n",
    "* The model: What does our model look like?\n",
    "* The training of the model: How does aa model perform while it learns?\n",
    "* The predictions of the model: How accurate are the predictions?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0bca3c7",
   "metadata": {},
   "source": [
    "## Big Data\n",
    "What is a good way to train a model? Give it a bigger dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595e03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a bigger set of data.\n",
    "X = tf.range(-100, 100, 4)\n",
    "y = X + 10\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e3fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbb9d193",
   "metadata": {},
   "source": [
    "### Splitting Data\n",
    "Need to split my complete data set into a training set and a test set\n",
    "\n",
    "**NOTE: There are typically 3 sets to split the data with**\n",
    "1. **Training Set**: Typically 70-80% of the data available used to train the model\n",
    "2. **Validation Set**: The data the model gets tuned on. Typically 10-15%.\n",
    "3. **Test Set**: The model gets evaluated on this data to teest what it has learned. Typically 10-15% of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2aa9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figuring out the Training and Test Set Sizes\n",
    "total_units = len(X)\n",
    "total_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abbb5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training set (80%)\n",
    "# NOTE: Typically, we should shuffle the data before splitting\n",
    "\n",
    "X_train = X[:int(total_units * 0.8)]\n",
    "y_train = y[:int(total_units * 0.8)]\n",
    "\n",
    "X_test = X[int(total_units * 0.8):]\n",
    "y_test = y[int(total_units * 0.8):]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c942bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the data\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(X_train, y_train, c='b', label='Training Data')\n",
    "plt.scatter(X_test, y_test, c='g', label='Test Data')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e3dc2c8",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d24808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create Model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,), name='InputLayer'),\n",
    "    tf.keras.layers.Dense(100, activation=tf.keras.activations.relu, name='HiddenLayer-1'),\n",
    "    tf.keras.layers.Dense(1, name='OutputLayer'),\n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.legacy.Adam(lr=0.005),\n",
    "             metrics=['mae'])\n",
    "\n",
    "\n",
    "# 3. Fit Model\n",
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11076386",
   "metadata": {},
   "source": [
    "### Visualizing the model\n",
    "\n",
    "Visualizing the model can be done with a handful of tools.\n",
    "\n",
    "* Summary: Looking at the summary of the model and what it looks like.\n",
    "* Diagram: Looking at the diagram of the model.\n",
    "* Plot: Plotting the predictions of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee079ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06956373",
   "metadata": {},
   "source": [
    "* Total params: the total parameters in the model.\n",
    "* Trainable params: the parameters (patterns) the model can update as it trains.\n",
    "* Non-trainable params: the parameters (patterns) that the model does not update as it trains. This occurrs when using an already trained model from transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e7fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc676dca",
   "metadata": {},
   "source": [
    "#### Visualizing the Predictions\n",
    "\n",
    "Plotting predictions against the actual values can help better visualize the model. This is often in the form of y_test or y_true versus y_pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df72a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Some predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a plotting function\n",
    "def plot_predictions(train_data=X_train, \n",
    "                     train_labels=y_train,\n",
    "                     test_data=X_test,\n",
    "                     test_labels=y_test,\n",
    "                     predictions=y_pred):\n",
    "    \"\"\"\n",
    "    Plots training data, test data, and compares predictions against actual valus.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(train_data, train_labels, c='b', label='Training Data')\n",
    "    plt.scatter(test_data, test_labels, c='g', label='Test Data')\n",
    "    plt.scatter(test_data, predictions, c='r', label='Predictions')\n",
    "    plt.legend()\n",
    "\n",
    "plot_predictions()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7fd89526",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "Depending on the problem, there will be different evaluation metrics to evaluate your model's performance.\n",
    "\n",
    "Common Regression Metrics:\n",
    "* **Mean Absolute Error**: The average absolute value of the difference between the prediction and the actual value.\n",
    "* **Mean Square Error**: The average of the square of the difference between the prediction and the actual value.\n",
    "  - Note: This is useful because the larger the difference, the MSE is drastically larger than just looking at the difference between the prediction and the actual value. TLDR: larger erros are more significant than smaller errors.\n",
    "* **Huber**: Combination of MSE and MAE. Less sensitive to outliers than MSE, but more sensitive to larger errors than MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f03150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef16fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = tf.metrics.mean_absolute_error(y_true=tf.squeeze(y_test), y_pred=tf.squeeze(y_pred))\n",
    "mse = tf.metrics.mean_squared_error(y_true=tf.squeeze(y_test), y_pred=tf.squeeze(y_pred))\n",
    "mae, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc13483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, pred):\n",
    "    return tf.metrics.mean_absolute_error(y_true=tf.squeeze(y_true), y_pred=tf.squeeze(pred))\n",
    "\n",
    "def mse(y_true, pred):\n",
    "    return tf.metrics.mean_squared_error(y_true=tf.squeeze(y_true), y_pred=tf.squeeze(pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ab2df93",
   "metadata": {},
   "source": [
    "### Resetting and Iterating My Model to Optimize It\n",
    "\n",
    "Going to test out 3 experiments with the same data as before.\n",
    "\n",
    "1. Trial-1: Simple Model\n",
    "2. Trial-2: Increase epochs to 100\n",
    "3. Trial-3: Add a 2nd Hidden Layer with epochs at 100\n",
    "4. Trial-4: Add a 2nd Hidden Layer with epochs at 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6adc796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting up the data and setup\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "X = tf.range(-100, 100, 4)\n",
    "y = X + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7367de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Data\n",
    "num_training_points = int(len(X) * 0.8)\n",
    "\n",
    "X_train = X[:num_training_points]\n",
    "y_train = y[:num_training_points]\n",
    "\n",
    "X_test = X[num_training_points:]\n",
    "y_test = y[num_training_points:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "663b0daf",
   "metadata": {},
   "source": [
    "#### Trial-1: Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d49f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create Model\n",
    "model_1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,), name='InputLayer'),\n",
    "    tf.keras.layers.Dense(50, activation=tf.keras.activations.relu, name='HiddenLayer-1'),\n",
    "    tf.keras.layers.Dense(1, name='OutputLayer')\n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "model_1.compile(optimizer=tf.keras.optimizers.legacy.Adam(lr=0.005),\n",
    "              loss=tf.keras.losses.mae)\n",
    "\n",
    "# 3. Fit Model\n",
    "model_1.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065e188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the Model\n",
    "predictions_1 = model_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2928ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Model\n",
    "plot_predictions(train_data=X_train, \n",
    "                 train_labels=y_train,\n",
    "                 test_data=X_test,\n",
    "                 test_labels=y_test,\n",
    "                 predictions=predictions_1)\n",
    "\n",
    "mae_1 = mae(y_test, predictions_1 )\n",
    "mse_1 = mse(y_test, predictions_1 )\n",
    "mae_1, mse_1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86712ce2",
   "metadata": {},
   "source": [
    "#### Trial-2: Epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f01545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create Model\n",
    "model_2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,), name='InputLayer'),\n",
    "    tf.keras.layers.Dense(50, activation=tf.keras.activations.relu, name='HiddenLayer-1'),\n",
    "    tf.keras.layers.Dense(1, name='OutputLayer')\n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "model_2.compile(optimizer=tf.keras.optimizers.legacy.Adam(lr=0.005),\n",
    "              loss=tf.keras.losses.mae)\n",
    "\n",
    "# 3. Fit Model\n",
    "model_2.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff0c910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the Model\n",
    "predictions_2 = model_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c735f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Model\n",
    "plot_predictions(train_data=X_train, \n",
    "                 train_labels=y_train,\n",
    "                 test_data=X_test,\n",
    "                 test_labels=y_test,\n",
    "                 predictions=predictions_2)\n",
    "\n",
    "mae_2 = mae(y_test, predictions_2 )\n",
    "mse_2 = mse(y_test, predictions_2 )\n",
    "mae_2, mse_2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2681ead",
   "metadata": {},
   "source": [
    "#### Trial-3: Epochs-100, Hidden Layers=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e47bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create Model\n",
    "model_3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,), name='InputLayer'),\n",
    "    tf.keras.layers.Dense(50, activation=tf.keras.activations.relu, name='HiddenLayer-1'),\n",
    "    tf.keras.layers.Dense(50, activation=tf.keras.activations.relu, name='HiddenLayer-2'),\n",
    "    tf.keras.layers.Dense(1, name='OutputLayer')\n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "model_3.compile(optimizer=tf.keras.optimizers.legacy.Adam(lr=0.005),\n",
    "              loss=tf.keras.losses.mae)\n",
    "\n",
    "# 3. Fit Model\n",
    "model_3.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01647180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the Model\n",
    "predictions_3 = model_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab2663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Model\n",
    "plot_predictions(train_data=X_train, \n",
    "                 train_labels=y_train,\n",
    "                 test_data=X_test,\n",
    "                 test_labels=y_test,\n",
    "                 predictions=predictions_3)\n",
    "\n",
    "mae_3 = mae(y_test, predictions_3 )\n",
    "mse_3 = mse(y_test, predictions_3 )\n",
    "mae_3, mse_3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99da2bde",
   "metadata": {},
   "source": [
    "#### Trial 4: Epochs=500, Hidden Layers=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e5188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create Model\n",
    "model_4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,), name='InputLayer'),\n",
    "    tf.keras.layers.Dense(50, activation=tf.keras.activations.relu, name='HiddenLayer-1'),\n",
    "    tf.keras.layers.Dense(50, activation=tf.keras.activations.relu, name='HiddenLayer-2'),\n",
    "    tf.keras.layers.Dense(1, name='OutputLayer')\n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "model_4.compile(optimizer=tf.keras.optimizers.legacy.Adam(lr=0.005),\n",
    "              loss=tf.keras.losses.mae)\n",
    "\n",
    "# 3. Fit Model\n",
    "model_4.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c820ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the Model\n",
    "predictions_4 = model_4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b593e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Model\n",
    "plot_predictions(train_data=X_train, \n",
    "                 train_labels=y_train,\n",
    "                 test_data=X_test,\n",
    "                 test_labels=y_test,\n",
    "                 predictions=predictions_4 )\n",
    "\n",
    "mae_4 = mae(y_test, predictions_4 )\n",
    "mse_4 = mse(y_test, predictions_4 )\n",
    "mae_4, mse_4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9beafb3",
   "metadata": {},
   "source": [
    "#### Comparing Each Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = [['model_1', mae_1.numpy(), mse_1.numpy()],\n",
    "                 ['model_2', mae_2.numpy(), mse_2.numpy()],\n",
    "                 ['model_3', mae_3.numpy(), mse_3.numpy()],\n",
    "                 ['model_4', mae_4.numpy(), mse_4.numpy()]]\n",
    "\n",
    "all_results = pd.DataFrame(model_results, columns=['model', 'mae', 'mse'])\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad00a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_3, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b00ce96",
   "metadata": {},
   "source": [
    "## Tracking Experiments\n",
    "\n",
    "A good habit for machine learning is to track experiments and their corresponding results.\n",
    "\n",
    "Useful tools to help track experiments:\n",
    "* TensorBoard: Component of the TensorFlow library to help track modeling experiments.\n",
    "* Weights & Biases: tool used for tracking experiments (Should def look this one up!)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0a00663",
   "metadata": {},
   "source": [
    "## Saving Our Models\n",
    "\n",
    "Saving out models allows us to use them outside of the place they were trained. \n",
    "\n",
    "* TensorFlow Docs: https://www.tensorflow.org/tutorials/keras/save_and_load\n",
    "* Saving model can be done by `model.save(\"savedirpath\")` or `model.save(\"h5filepath.h5\")`\n",
    "* Loading model can be done by `tf.keras.models.load_model(\"savedirpath\")` or `tf.keras.models.load_model(\"h5filepath.h5\")`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
