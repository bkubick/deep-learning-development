{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24747fd8-5301-4c67-9aaf-5021fa0a3370",
   "metadata": {},
   "source": [
    "# TensorFlow Developer Exam Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0ff721-70dc-4bc1-9b5a-18b5a0a00de0",
   "metadata": {},
   "source": [
    "## Notebook Details\n",
    "\n",
    "This section goes over the Table of Contents for this notebook, along with listing out the resources referenced in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2de765-066a-4d8f-a5b0-84300977bbbb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Table of Contents\n",
    "\n",
    "The various sections and links to those section in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd49600a-e015-434a-a05c-a72be4480f59",
   "metadata": {},
   "source": [
    "#### 1. Guide to TensorFlow & Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a5110f-7789-42ca-ad57-1a1b21b81f75",
   "metadata": {},
   "source": [
    "1. TensorFlow Inputs & Outputs Table\n",
    "2. Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b1d9b-3225-4d67-b622-c401c218275a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2. TensorFlow Certificate Candidate Handbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83eb652-2dd3-41b2-9840-31ee3d6a25bf",
   "metadata": {},
   "source": [
    "1. TensorFlow Development Skills\n",
    "    - 1.1. Know how to program in Python, resolve Python issues, and compile and run Python programs in PyCharm.\n",
    "    - 1.2. Know how to find information about TensorFlow APIs, including how to find guides and API references on tensorflow.org.\n",
    "    - 1.3. Know how to debug, investigate, and solve error messages from the TensorFlow API.\n",
    "    - 1.4. Know how to search beyond tensorflow.org, as and when necessary, to solve your TensorFlow questions.\n",
    "    - 1.5. Know how to create ML models using TensorFlow where the model size is reasonable for the problem being solved.\n",
    "    - 1.6. Know how to save ML models and check the model file size.\n",
    "    - 1.7. Understand the compatibility discrepancies between different versions of TensorFlow.\n",
    "2. Building and training neural network models using TensorFlow 2.x\n",
    "    - 2.1. Use TensorFlow 2.x.\n",
    "    - 2.2. Build, compile and train machine learning (ML) models using TensorFlow.\n",
    "    - 2.3. Preprocess data to get it ready for use in a model.\n",
    "    - 2.4. Use models to predict results.\n",
    "    - 2.5. Build sequential models with multiple layers.\n",
    "    - 2.6. Build and train models for binary classification.\n",
    "    - 2.7. Build and train models for multi-class categorization.\n",
    "    - 2.8. Plot loss and accuracy of a trained model.\n",
    "    - 2.9. Identify strategies to prevent overfitting, including augmentation and dropout.\n",
    "    - 2.10. Use pretrained models (transfer learning).\n",
    "    - 2.11. Extract features from pre-trained models.\n",
    "    - 2.12. Ensure that inputs to a model are in the correct shape.\n",
    "    - 2.13. Ensure that you can match test data to the input shape of a neural network.\n",
    "    - 2.14. Ensure you can match output data of a neural network to specified input shape for test data.\n",
    "    - 2.15. Understand batch loading of data.\n",
    "    - 2.16. Use callbacks to trigger the end of training cycles.\n",
    "    - 2.17. Use datasets from different sources.\n",
    "    - 2.18. Use datasets in different formats, including json and csv.\n",
    "    - 2.19. Use datasets from tf.data.datasets.\n",
    "3. Image Classification\n",
    "    - 3.1. Define Convolutional neural networks with Conv2D and pooling layers.\n",
    "    - 3.2. Build and train models to process real-world image datasets.\n",
    "    - 3.3. Understand how to use convolutions to improve your neural network.\n",
    "    - 3.4. Use real-world images in different shapes and sizes.\n",
    "    - 3.5. Use image augmentation to prevent overfitting.\n",
    "    - 3.6. Use ImageDataGenerator.\n",
    "    - 3.7. Understand how ImageDataGenerator labels images based on the directory structure.\n",
    "4. Natural language processing (NLP)\n",
    "    - 4.1. Build natural language processing systems using TensorFlow.\n",
    "    - 4.2. Prepare text to use in TensorFlow models.\n",
    "    - 4.3. Build models that identify the category of a piece of text using binary categorization\n",
    "    - 4.4. Build models that identify the category of a piece of text using multi-class categorization\n",
    "    - 4.5. Use word embeddings in your TensorFlow model.\n",
    "    - 4.6. Use LSTMs in your model to classify text for either binary or multi-class categorization.\n",
    "    - 4.7. Add RNN and GRU layers to your model.\n",
    "    - 4.8. Use RNNS, LSTMs, GRUs and CNNs in models that work with text.\n",
    "    - 4.9. Train LSTMs on existing text to generate text (such as songs and poetry)\n",
    "5. Time series, sequences and predictions\n",
    "    - 5.1. Train, tune and use time series, sequence and prediction models.\n",
    "    - 5.2. Train models to predict values for both univariate and multivariate time series.\n",
    "    - 5.3. Prepare data for time series learning.\n",
    "    - 5.4. Understand Mean Absolute Error (MAE) and how it can be used to evaluate accuracy of sequence models.\n",
    "    - 5.5. Use RNNs and CNNs for time series, sequence and forecasting models.\n",
    "    - 5.6. Identify when to use trailing versus centred windows.\n",
    "    - 5.7. Use TensorFlow for forecasting.\n",
    "    - 5.8. Prepare features and labels.\n",
    "    - 5.9. Identify and compensate for sequence bias.\n",
    "    - 5.10. Adjust the learning rate dynamically in time series, sequence and prediction models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494b4cb4-9967-4987-a083-cd8b6d7ca3e4",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "The various resources/articles used to create this notebook, along with various resources/articles that are very useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ae5fd-9cf7-4088-ae25-ddb334097fed",
   "metadata": {},
   "source": [
    "1. [Article by Judy Traj](https://medium.com/@judytraj007/getting-the-google-tensorflow-developer-certification-51cf1e4c2bf9)\n",
    "2. [Article by R. Barbero](https://medium.com/@rbarbero/tensorflow-certification-tips-d1e0385668c8)\n",
    "3. [Github Repo of Tensorflow-Certificate Study Guide](https://github.com/kolasniwash/tensorflow-certification-study-guide)\n",
    "4. [TensorFlow: Guide to Getting Started](https://www.kaggle.com/code/nicholasjhana/tensorflow-guide-to-getting-started/notebook)\n",
    "5. [LinkedIn Article by Vivek Bomabtkar](https://www.linkedin.com/pulse/tensorflow-developer-certification-vivek-bombatkar/)\n",
    "6. [LLM Notebook in TensorFlow by FOUCARDM on Kaggle](https://www.kaggle.com/code/foucardm/tensorflow-certification-guide-text-data/notebook)\n",
    "7. [Bidirectional RNN Architecture](https://www.geeksforgeeks.org/bidirectional-lstm-in-nlp/)\n",
    "8. [LSTM Architecture](https://www.geeksforgeeks.org/deep-learning-introduction-to-long-short-term-memory/)\n",
    "9. [GRU Architecture](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be)\n",
    "10. [Metrics in Timeseries Forecasting](https://mlpills.dev/time-series/error-metrics-for-time-series-forecasting/)\n",
    "11. [Univariate Time Series Forecasting with TensorFlow](https://www.kaggle.com/code/nicholasjhana/univariate-time-series-forecasting-with-keras/notebook)\n",
    "12. [Multi-Variate Time Series Forecasting with TensorFlow](https://www.kaggle.com/code/nicholasjhana/multi-variate-time-series-forecasting-tensorflow/notebook)\n",
    "13. [Reducing Overfitting](https://www.kdnuggets.com/2019/12/5-techniques-prevent-overfitting-neural-networks.html)\n",
    "14. [Data Augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation)\n",
    "15. [Layer Regularizers](https://johnthas.medium.com/regularization-in-tensorflow-using-keras-api-48aba746ae21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7f965c-d91e-4f60-84e7-a0cce3a14b7a",
   "metadata": {},
   "source": [
    "## Guide to TensorFlow & Modeling\n",
    "\n",
    "TensorFlow and Modeling has aaaaalotttt of information, but there are certain key things that are extremely useful to keep in mind. This section will go over the information that is absolutely crucial in creating good models with TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f44e4-e36b-4f66-b42e-3e6d4ba23a82",
   "metadata": {},
   "source": [
    "### 1. TensorFlow Inputs & Outputs Table\n",
    "\n",
    "When building models, there are certain things to remember depending on the specific problem being modeled. The following tables summarize the input/output and model configurations for each type of the various problems being solved [4]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce808ce-189c-433d-a4e6-900a82e1d142",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Inputs\n",
    "\n",
    "Input shapes depend on the type of problem and network architecture. Input shape can be defined in the first layer of the network either calling the `input_shape` parameter or using the `tf.keras.layers.Input` class.\n",
    "\n",
    "| Data Type      | Input Shape                                      |\n",
    "| :--------------| :------------------------------------------------|\n",
    "| Image          | (image height, image width, number of channels)  |\n",
    "| Sequence       | (number of sequence steps, number of features)   |\n",
    "| Structured     | (samples/batch size, features)                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93325e51-4c98-4b84-b538-43d395ffed90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Outputs\n",
    " \n",
    "| Problem Type\t        | Output Neurons        | Target Format   |\tLoss Type\t                               | Last Neuron Activation |\n",
    "| :---------------------| :-------------------- | :-------------- | :----------------------------------------- | :--------------------- |\n",
    "| Binary Classification\t| 1\t                    | Binary\t      | binary_crossentropy                        | sigmoid                |\n",
    "| Multi Classification\t| Number of classes  \t| One-Hot Encoded | categorical_crossentropy                   | softmax                |\n",
    "| Multi Classification\t| Number of classes\t    | Label Encoded\t  | sparse_categorical_crossentropy\t           | softmax                |\n",
    "| Regression\t        | Number of predictions\t| Numeric\t      | Any regression metric: MSE/RMSE/MSLE/Huber | None                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1408169b-e5fa-49ae-b888-87344d741859",
   "metadata": {},
   "source": [
    "### 2. Overfitting\n",
    "\n",
    "Overfitting occurs when the model's predictions become highly variant. That is we see large variations between predictions in an effort to fit closer to the training set. The opposite can also occur, underfitting where the predictions do not generalize effectively.\n",
    "\n",
    "There are a few methods to recognize if the model overfit the training data.\n",
    "\n",
    "* Training loss declines while validation loss is constant or rises.\n",
    "* A large gap between the training accuracy/ROC AUC/etc and the validation.\n",
    "* Validation score does not change while validation loss declines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9214f107-0772-4602-8dae-909844cf4c26",
   "metadata": {},
   "source": [
    "## TensorFlow Certificate Candidate Handbook\n",
    "\n",
    "The TensorFlow certificate exam provides a handbook that gives details on what to know for the exam. This section goes over each section of the Handbook, providing sample information regarding each question.\n",
    "\n",
    "* [TensorFlow Certificate Candidate Handbook](https://www.tensorflow.org/static/extras/cert/TF_Certificate_Candidate_Handbook.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d43c254-65f2-4442-ab38-b0f8d61f3b06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "892e7aea-5377-41df-95fe-7331f4b6af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066fb217-e776-4357-a4e5-4767326ddcb9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Notebook Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8ab8b5c-c311-4e33-a351-122f25c440cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook last run (end-to-end): 2023-10-01 20:09:59.203369\n"
     ]
    }
   ],
   "source": [
    "print(f'Notebook last run (end-to-end): {datetime.datetime.now()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c333a-4cf4-4ee1-9bf8-c3f25d397638",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. TensorFlow Development Skills\n",
    "You need to demonstrate that you understand how to develop software programs using TensorFlow and that you can find the information you need to work as an ML practitioner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de92e3c0-c5d2-466d-8192-17cd1147eb04",
   "metadata": {},
   "source": [
    "#### 1.1. Know how to program in Python, resolve Python issues, and compile and run Python programs in PyCharm.\n",
    "* [Downloading PyCharm](https://www.jetbrains.com/pycharm/)\n",
    "* [Learn PyCharm](https://www.jetbrains.com/pycharm/learn/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0b7db3-face-42d7-af9c-1fe737a56791",
   "metadata": {},
   "source": [
    "#### 1.2. Know how to find information about TensorFlow APIs, including how to find guides and API references on tensorflow.org.\n",
    "* [API Documentation](https://www.tensorflow.org/api_docs/python/tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287958a3-1b41-4b68-b7ad-307b5f5eb108",
   "metadata": {},
   "source": [
    "#### 1.3. Know how to debug, investigate, and solve error messages from the TensorFlow API.\n",
    "* [Debugging Tips](https://towardsdatascience.com/debugging-in-tensorflow-392b193d0b8)\n",
    "* [TensorFlow Errors](https://www.tensorflow.org/api_docs/python/tf/errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e856802-1d2d-4678-89d1-4147237a760f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1.4. Know how to search beyond tensorflow.org, as and when necessary, to solve your TensorFlow questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33ecfe2-a626-4a01-a883-d69df8ae2400",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1.5. Know how to create ML models using TensorFlow where the model size is reasonable for the problem being solved.\n",
    "\n",
    "* Sequential Model\n",
    "* Functional API Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82213540-2f7d-41bc-b5c8-a1e7959d65ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Sequential Model\n",
    "\n",
    "* `tf.keras.models.Sequential`\n",
    "* https://www.tensorflow.org/api_docs/python/tf/keras/Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "032fc5c1-dfad-4cfe-93e3-166502bdec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(2,), name='input_layer'),\n",
    "    tf.keras.layers.Dense(10, activation='relu', name='hidden_layer_1'),\n",
    "    tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid, name='output'),\n",
    "], name='sequential_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d9c282-c764-45e2-94f0-256aa07787aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Functional API\n",
    "\n",
    "* `tf.keras.models.Model`\n",
    "* https://www.tensorflow.org/api_docs/python/tf/keras/Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdc49b74-b299-4106-a7b8-7b0c1de7b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(2,), name='input_layer')\n",
    "x = tf.keras.layers.Dense(10, activation='relu', name='hidden_layer_1')(inputs)\n",
    "outputs = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid, name='output')(x)\n",
    "\n",
    "functional_model = tf.keras.models.Model(inputs, outputs, name='functional_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f826f3d0-ca77-4860-9a8e-8c259d9ce89c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1.6. Know how to save ML models and check the model file size.\n",
    "\n",
    "Models can be saved in one of two formats: `h5` or `TF`.\n",
    "\n",
    "* [Saving and Loading Models Article](https://www.kdnuggets.com/2021/02/saving-loading-models-tensorflow.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f3785c-a274-4b9a-91d8-a1fbc40d08ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "332d3a8b-2854-4017-a956-308284cf3132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./models/sequential_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/sequential_model/assets\n"
     ]
    }
   ],
   "source": [
    "sequential_model.save('./models/sequential_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9470a43-3b39-4d5f-b28e-d54bfe638acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonkubick/Code/deep-learning-development/env/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "functional_model.save('./models/functional_model', save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad1dc5-3602-473f-be57-01b8a8aa0a0e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fe22232-4bc5-451f-a4c7-9d1dcf6a2c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "sequential_model_loaded = tf.keras.models.load_model('./models/sequential_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54b143ef-bc8c-4379-802d-01d0dbf24b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "functional_model_loaded = tf.keras.models.load_model('./models/functional_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32776ea-9866-4efa-b40a-6cf37218b323",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Checking File Size\n",
    "\n",
    "**TODO** Come back to check this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "533ba01b-ceef-41e1-aecc-1609876fb51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50965"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_size = 0\n",
    "for dir, _, files in os.walk('./models/sequential_model'):\n",
    "    total_size += sum([os.path.getsize(f'{dir}/{file}') for file in files])\n",
    "\n",
    "total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a79851e-843e-4e15-adcc-21367d39c79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16016"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize('./models/functional_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef76b4-9cc6-4f2f-bb74-74468e3adc5f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1.7. Understand the compatibility discrepancies between different versions of TensorFlow.\n",
    "\n",
    "* https://www.tensorflow.org/guide/migrate/tf1_vs_tf2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cf7e62-0a12-4000-b9d9-b1f26bceb5bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2. Building and training neural network models using TensorFlow 2.x\n",
    "\n",
    "You need to understand the foundational principles of machine learning (ML) and deep learning (DL) using TensorFlow 2.x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a8e7c3-e662-4e8d-92a1-9062fa5d1064",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.1. Use TensorFlow 2.x.\n",
    "\n",
    "* https://blog.tensorflow.org/2019/09/tensorflow-20-is-now-available.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34d9d344-2316-459e-877c-8078ebdbcd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d50afc-51be-42ee-a007-4fb51491ead2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.2. Build, compile and train machine learning (ML) models using TensorFlow.\n",
    "\n",
    "**Building Models**\n",
    "* `tf.keras.models.Sequential`: Simple way of creating models with a single input, and are sequentially setup layers.\n",
    "* `tf.keras.models.Model`: More customizable way of creating models, allowing multiple inputs, parallel/wide networks, and deep networks.\n",
    "\n",
    "**Compiling Models**\n",
    "* `model.compile`: Used to set how the model should learn through setting the optimizer and loss function.\n",
    "\n",
    "**Training Models**\n",
    "* `model.fit`: Used to actually train the models through passing in all the training specific information (data, epochs, validation data, batch size, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f79350e8-129d-4edd-8f2c-fc607a6b0c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model (Sequential API)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(5),\n",
    "])\n",
    "\n",
    "# Build Model (Functional API)\n",
    "inputs = tf.keras.layers.Input(shape=(1,))\n",
    "outputs = tf.keras.layers.Dense(5)(inputs)\n",
    "model = tf.keras.models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f935504-5174-4392-900c-891f7070f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(loss='mae',\n",
    "              optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "              metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b96943e-e7c5-45ea-b854-c26490b35999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "history = model.fit(\n",
    "    x=[1],\n",
    "    y=[[1,2, 3, 4, 5]],\n",
    "    epochs=1,\n",
    "    callbacks=[],\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ec02ea-f892-46a2-aba8-a710391d5310",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.3. Preprocess data to get it ready for use in a model.\n",
    "\n",
    "* Categorical Data needs to be converted to a numerical representation\n",
    "    - Encode data using `sklearn.preprocessing.LabelEncoder`\n",
    "    - One-hot Encode data using `sklearn.preprocessing.OneHotEncoder` or `tf.one_hot`\n",
    "* Preprocessing Layers\n",
    "    - [Preprocessing Layers](https://www.tensorflow.org/guide/keras/preprocessing_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf905d5-3aeb-40af-94f2-ca5734c107b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.4. Use models to predict results.\n",
    "\n",
    "* `model.predict`: Used to predict the results given the corresponding inputs.\n",
    "\n",
    "**NOTE**: the prediction outputs the probabilities in classification models, or the value in regression models. This is problematic for classification models, because classification means that is should be one value of a set of options rather than a probability.\n",
    "\n",
    "* `tf.argmax`: Grabs the index of the maximum value (used to grab the corresponding classification class).\n",
    "* `tf.round`: Rounds the probabilities. This doesn't always work for multi-class classification because all the probs can round to 0 if there are many classifications it can fall into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27ca230e-b638-46a4-bdb7-6975b89a74ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=2>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax([0.1, 0.2, 0.6, 0.12, 0.14])  # Highest index is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d950ff38-2be0-4053-bce4-e35a4dd5899b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=float32, numpy=array([0., 1., 0., 1., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.round([0.1, 0.51, 0.3, 0.6, 0.12, 0.14])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaeaac4-7a56-4e7e-a23a-b4c0f2f138b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.5. Build sequential models with multiple layers.\n",
    "\n",
    "* `tf.keras.models.Sequential`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaf9680b-899f-468f-9f83-b8c66e343f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,), name='Input'),\n",
    "    tf.keras.layers.Dense(5),\n",
    "    tf.keras.layers.Dense(5),\n",
    "    tf.keras.layers.Dense(5),\n",
    "    tf.keras.layers.Dense(1, name='Output'),\n",
    "], name='SequentialModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936b8dbe-6676-4094-bdc3-09392c966a5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.6. Build and train models for binary classification.\n",
    "\n",
    "Binary classification is when the output is either 1 or 0 (only two choices).\n",
    "\n",
    "* Ouput Shape = `(1,)`\n",
    "* Output Activation Function = `sigmoid`\n",
    "* Loss Function = `binary_crossentropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74d1af02-746e-4d45-9702-36cb710facfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Model\n",
    "binary_classification_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(3,)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "], name='binary_classification')\n",
    "\n",
    "# Binary Model Compiling\n",
    "binary_classification_model.compile(loss='binary_crossentropy',\n",
    "                                    optimizer=tf.keras.optimizers.legacy.Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773465c8-3d55-4c04-beb8-b72983708047",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.7. Build and train models for multi-class categorization.\n",
    "\n",
    "Multi-class categorization is when the output is more than two options. This requires converting each category into a numerical representation.\n",
    "\n",
    "* Output Shape = `(num_classes,)`\n",
    "* Output Activation Function = `softmax`\n",
    "* Loss Function = `categorical_crossentropy` if one-hot encoded format; `spare_categorical_crossentropy` if label encoded format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3be59737-f9e9-445b-bdcd-e8a75b7246fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.constant(['dog', 'cat', 'bird', 'dog'])\n",
    "total_categories = 3  # dog, cat, bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "71a059cc-b70a-4104-93ea-2a87105a9727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding Labels (With sklearn)\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8b90bb2b-9a76-4601-acae-584b59b2c16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       " array([[0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.]], dtype=float32)>,\n",
       " array([[0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.]]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-Hot-Encoding Labels (With TensorFlow)\n",
    "one_hot_encoded_labels_tf = tf.one_hot(encoded_labels, total_categories)\n",
    "\n",
    "# One-Hot-Encoding Labels (With sklearn)\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "one_hot_encoded_labels_sklearn = one_hot_encoder.fit_transform(encoded_labels.reshape(-1, 1))\n",
    "\n",
    "one_hot_encoded_labels_tf, one_hot_encoded_labels_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "985f6474-99b2-468e-aa66-5281e6066fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-class Model\n",
    "multiclass_classification_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(total_categories, activation='sigmoid'),\n",
    "], name='binary_classification')\n",
    "\n",
    "# Multi-class Model Compiling\n",
    "\n",
    "# Using with one_hot_encoded_labels_tf when fitting\n",
    "multiclass_classification_model.compile(loss='categorical_crossentropy',\n",
    "                                        optimizer=tf.keras.optimizers.legacy.Adam())\n",
    "\n",
    "# Using with encoded_labels when fitting\n",
    "multiclass_classification_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                                        optimizer=tf.keras.optimizers.legacy.Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf054d5a-0048-4272-ae9c-f0de2ab63b5c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.8. Plot loss and accuracy of a trained model.\n",
    "\n",
    "When fitting a model, a history object is returned with the designated metrics the model was compiled with, along with the loss. This can be plotted using matplotlib.\n",
    "\n",
    "* [History Object](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History): The History object is associated as a callback that is automatically applied to the model when fitting and is returned by the fit method.\n",
    "\n",
    "Some things to consider for the loss curves include:\n",
    "* Ideally, the loss curve vor the validation loss and training loss will follow each other\n",
    "* Point where training loss continues to decrease, but validation loss starts to stabilize implies `overfitting` (see section 2.9 below).\n",
    "\n",
    "**NOTE** I have a personal toolbox, [py-learning-toolbox](https://github.com/bkubick/py-learning-toolbox), that will plot the histroy curve using the function, `ml_toolbox.analysis.history.plot_history`, and the designated metric desired to plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56a028b-2dfe-4970-a93d-8844fa45ca77",
   "metadata": {},
   "source": [
    "![image](screenshots/loss_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a5fa4b-f22a-4a7b-92b0-7521582dda0c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.9. Identify strategies to prevent overfitting, including augmentation and dropout.\n",
    "\n",
    "Overfitting occurs when the model learns the training data too well, that it can't predict test data or validation well. There are a handful of things that can be done to mitigate/prevent overfitting [Prevent Overfitting](https://www.kdnuggets.com/2019/12/5-techniques-prevent-overfitting-neural-networks.html).\n",
    "\n",
    "* **Decrease complexity of model**: Not much to this, and not much to do to determine best route of simplifying model. Ultimately, just want to reduce the number of trainable parameters in the model.\n",
    "* **Early Stopping**: A callback that can be implemented to stop the model from training once the validation loss is no longer decreasing.\n",
    "* **More Data**: An obvious thing to do is add more data, but this isn't always possible.\n",
    "* **Data Augmentation**: Transforming data to expand the dataset, and give a model various ways of viewing data. Specifically for image classification, popular data augmentation techniques include flipping image, rotating image, zoom image, etc.\n",
    "* **Regularization**: A technique used to reduce complexity of a model through adding penalty terms to the loss function. This is done by adding regularizers to the corresponding layer through `kernel_regularizer`, `bias_regularizer`, or `activity_regularizer` kwarg.\n",
    "  \n",
    "    | L1 Regularization                                | L2 Regularization                         |\n",
    "    | :-----------------                               | :----------------                         |\n",
    "    | Penalizes sum of absolute values of weights      | Penalizes sum of square values of weights |\n",
    "    | Generates model that is simple and interpretable | Able to learn complex data patterns       |\n",
    "    | Robust to outliers                               | Not robust to outliers                    |\n",
    "\n",
    "* **Dropout**: A technique that deactivates random neurons in the model while training, forcing each neuron to \"learn\", in theory, making each neuron more robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "52b69b41-2abd-4e26-b29e-cb4bfc6cdd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping Callback\n",
    "# `patience`: how many epochs without improvement before ending training\n",
    "# `start_from_epoch`: which epoch to start looking at stopping\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(patience=10, start_from_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9ac3876d-dce9-4b0b-ab5f-7c94540b163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation ImageDataGenerator (Not Preferred)\n",
    "data_augmented_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Data Augmentation (Preferred Method)\n",
    "data_augmentation_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomHeight(0.2),\n",
    "    tf.keras.layers.RandomWidth(0.2),\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "], name='DataAugmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dfee9210-ec86-4ed2-b711-a66f291292bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization\n",
    "regularization_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(5,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l1(0.01),\n",
    "                          bias_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                          activity_regularizer=tf.keras.regularizers.l1_l2(0.01, 0.01)),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "074c1c4f-6190-4181-b9b6-c24936442882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout\n",
    "dropout_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(5),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968c7c6d-97a7-4b4e-80ac-94ffa6b20287",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.10. Use pretrained models (transfer learning).\n",
    "\n",
    "Transfer learning can be done by utilizing state of the art architectures trained on signifcant data through various studies, allowing for powerful models without the need for extreme training.\n",
    "\n",
    "TensorFlow Hub provides various models that can be used for transfer learning.\n",
    "* https://www.tensorflow.org/hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7263dd97-4d9d-477f-967e-7edbee418163",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7860e9-b80c-4d8a-b628-da95cf3a2d56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.11. Extract features from pre-trained models.\n",
    "Feature extraction in transfer learning is when you take the underlying patterns (also called weights) a pretrained model has learned and adjust its outputs to be more suited to your problem. [[D. Bourke, Zero to Mastery](https://dev.mrdbourke.com/tensorflow-deep-learning/04_transfer_learning_in_tensorflow_part_1_feature_extraction/)]\n",
    "\n",
    "In short, use transfer learning as a non-trainable base model, then pass the output of that to one or multiple layers dedicated to a specific problem (i.e. image classification by taking a model that knows 1000 foods, and add output layer to limit it to a set of only 10 foods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6b8e6fae-cc44-4ada-9d0e-dbc3517e1035",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "x = base_model(inputs)\n",
    "outputs = tf.keras.layers.Dense(5)(x)  # Feature Extraction Used to dictate the outputs\n",
    "\n",
    "model = tf.keras.models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a1185-b670-4d65-9074-d0aff9759430",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.12. Ensure that inputs to a model are in the correct shape.\n",
    "\n",
    "Inputs to a model are the specific parameters associated with the problem that are used to predict the output. In TensorFlow, the `shape` keyword to each layer automatically applies batching to the data ahead of time, meaning all that has to be specified is the shape of the inputs.\n",
    "\n",
    "| Data Type      | Input Shape                                      |\n",
    "| :--------------| :------------------------------------------------|\n",
    "| Image          | (image height, image width, number of channels)  |\n",
    "| Text           | (1,) - the string of the text                    |\n",
    "| Sequence       | (number of sequence steps, number of features)   |\n",
    "| Feed Forward   | (features)                   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ba2def3a-70f9-47e5-849d-e85ee8ce8465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None, 224, 224, 3]),\n",
       " TensorShape([None, 1]),\n",
       " TensorShape([None, 7]),\n",
       " TensorShape([None, 2]))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_input = tf.keras.layers.Input(shape=(224, 224, 3))\n",
    "text_input = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "sequence_input = tf.keras.layers.Input(shape=(7,))  # Window size of 7, 0 additional features\n",
    "feed_forward = tf.keras.layers.Input(shape=(2,))  # two features used to predict\n",
    "\n",
    "image_input.shape, text_input.shape, sequence_input.shape, feed_forward.shape  # The None is held for the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a939da-c04b-4951-9f66-ed948e59d121",
   "metadata": {},
   "source": [
    "#### 2.13. Ensure that you can match test data to the input shape of a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1572fe77-47b4-495e-804f-4299da0f1ce0",
   "metadata": {},
   "source": [
    "#### 2.14. Ensure you can match output data of a neural network to specified input shape for test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294089d6-4d33-4962-b63e-c2c2260a3c83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.15. Understand batch loading of data.\n",
    "\n",
    "Batching is the process of using multiple samples of data at a time while training, to provide memory efficiency, faster training, and improved generalization. This is done in one of two ways in TensorFlow, while fitting, or through the dataset itself.\n",
    "\n",
    "**NOTE** batch sizes in multiples of 8 typically work better with GPU's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "df5886ee-0fff-4d68-a25a-60ddd30a4ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x1551f4160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x1551f4160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x155259a00>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting with batches\n",
    "# Build Model (Sequential API)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(5),\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(loss='mae', optimizer=tf.keras.optimizers.legacy.Adam())\n",
    "\n",
    "# Train Model\n",
    "model.fit(\n",
    "    x=[1],\n",
    "    y=[[1,2, 3, 4, 5]],\n",
    "    epochs=1,\n",
    "    batch_size=1,  # Batch Size\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9fe32801-90dd-47a5-89d9-0f14616f7413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batching with dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3, 1, 33, 5, 3])\n",
    "batched_dataset = dataset.batch(3)\n",
    "batched_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1279b74c-fc6c-453f-9eda-ab005d615a8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.16. Use callbacks to trigger the end of training cycles.\n",
    "\n",
    "Callbacks are used when training a model, and are ran at the end of each epoch. They can be used for saving, logging, adjusting learning rates, ending training, etc.\n",
    "\n",
    "* https://www.tensorflow.org/api_docs/python/tf/keras/callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f04dfceb-9229-459b-8ba7-87738737cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to stop training once model stops improving\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping()\n",
    "\n",
    "# Used to store the model at the end of each epoch as a checkpoint.\n",
    "# This is useful when needing to stop training early and pickup where you left off.\n",
    "# Also useful to save the best trained model\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('./checkpoints')\n",
    "\n",
    "# Logs the metrics for each epoch to the corresponding CSV.\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('./logs/history.csv')\n",
    "\n",
    "# Reduces the learning rate by a factor when the learning stops (hits a plateau)\n",
    "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau()\n",
    "\n",
    "# LR Scheduler is used to update the learning rate for each epoch\n",
    "# This is useful when triying to determine the optimal learning rate\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch, lr: lr * 10 ** 2)\n",
    "\n",
    "# Custom callback\n",
    "lambda_callback = tf.keras.callbacks.LambdaCallback(on_batch_begin=lambda batch,logs: print(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1f4208-3747-4270-a588-a909697ca46f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.17. Use datasets from different sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d65b8-f9d1-4d19-8c3f-0607265bcdee",
   "metadata": {},
   "source": [
    "#### 2.18. Use datasets in different formats, including json and csv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9abb5e5-e2e8-4e0b-9ac7-7ab297e29a5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2.19. Use datasets from tf.data.datasets.\n",
    "\n",
    "* https://www.tensorflow.org/datasets/performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba123bb-97ff-4ef8-a493-533a89deff11",
   "metadata": {},
   "source": [
    "### 3. Image classification\n",
    "\n",
    "You need to understand how to build image recognition and object detection models with deep neural networks and convolutional neural networks using TensorFlow 2.x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45ac9dc-433c-468a-afa0-4fc742941594",
   "metadata": {},
   "source": [
    "#### 3.1. Define Convolutional neural networks with Conv2D and pooling layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79df9a5-9abc-423f-993e-c5ebbbbec3c3",
   "metadata": {},
   "source": [
    "#### 3.3. Understand how to use convolutions to improve your neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62842f8c-e1c0-4044-82dc-6d6b33b42b4f",
   "metadata": {},
   "source": [
    "#### 3.4. Use real-world images in different shapes and sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26b577e-7c80-4b17-995b-bbf3fe1f6712",
   "metadata": {},
   "source": [
    "#### 3.5. Use image augmentation to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e9324d-e824-46c1-955b-f466d5c16833",
   "metadata": {},
   "source": [
    "#### 3.6. Use ImageDataGenerator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e198f2c-8df7-4869-a5c6-ce20353e0fae",
   "metadata": {},
   "source": [
    "#### 3.7. Understand how ImageDataGenerator labels images based on the directory structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454c1cd-d3e8-4b85-adaa-24f923799595",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4. Natural language processing (NLP)\n",
    "\n",
    "You need to understand how to use neural networks to solve natural language processing problems using TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd965bad-d15e-4ded-8c0e-a3760573b1c5",
   "metadata": {},
   "source": [
    "#### 4.1. Build natural language processing systems using TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ec7750-1446-4f59-9847-f9dfc85b04dd",
   "metadata": {},
   "source": [
    "#### 4.2. Prepare text to use in TensorFlow models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72d1143-9089-4e9f-afed-82fff6b3f937",
   "metadata": {},
   "source": [
    "#### 4.3. Build models that identify the category of a piece of text using binary categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db0d43-bafa-4dfb-be9f-02d4e63e555c",
   "metadata": {},
   "source": [
    "#### 4.4. Build models that identify the category of a piece of text using multi-class categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe081b7-93d7-413d-9565-20d8fb4cb3e9",
   "metadata": {},
   "source": [
    "#### 4.5. Use word embeddings in your TensorFlow model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728ee55-f39c-484e-b5d2-774df5d2816c",
   "metadata": {},
   "source": [
    "#### 4.6. Use LSTMs in your model to classify text for either binary or multi-class categorization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfa67e3-d18e-4b68-94f3-e5340640135c",
   "metadata": {},
   "source": [
    "#### 4.7. Add RNN and GRU layers to your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3b5b1b-468a-42b8-8303-c7666b20062b",
   "metadata": {},
   "source": [
    "#### 4.8. Use RNNS, LSTMs, GRUs and CNNs in models that work with text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7fd645-03ab-43c2-92eb-34bc06fd6329",
   "metadata": {},
   "source": [
    "#### 4.9. Train LSTMs on existing text to generate text (such as songs and poetry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893e7eda-f0b8-45b4-86fd-1b8bc061e1af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5. Time series, sequences and predictions\n",
    "\n",
    "You need to understand how to solve time series and forecasting problems in TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d4b288-5abb-4750-92c6-bcf26e457117",
   "metadata": {},
   "source": [
    "#### 5.1. Train, tune and use time series, sequence and prediction models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df1ab11-ab5e-44a8-a600-109e86000127",
   "metadata": {},
   "source": [
    "#### 5.2. Train models to predict values for both univariate and multivariate time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da5fb03-8571-4da1-be7b-35a44059e31f",
   "metadata": {},
   "source": [
    "#### 5.3. Prepare data for time series learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca75342a-455c-407b-a7ff-107dbb901272",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 5.4. Understand Mean Absolute Error (MAE) and how it can be used to evaluate accuracy of sequence models.\n",
    "\n",
    "MAE is calculated by taking the absolute difference between the predicted and actual values and averaging them. [10]\n",
    "\n",
    "* **Advantages** MAE is simple and easy to interpret as the mean error is expressed in the same units as the original data. It is less sensitive to outliers compared to other error metrics such as mean squared error (MSE).\n",
    "* **Disadvantages** MAE does not distinguish between overestimation and underestimation and does not provide information about the direction or magnitude of individual errors. In addition, depending on your particular problem it may be seen as a disadvantage that it does not penalize wrong predictions as much as MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "487bff0c-e79e-44cc-a58f-18e4e61eebb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.metrics.mae([1, 2, 3, 4], [2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9544d1-9ec0-4e4a-9a74-645e8db0f46c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 5.5. Use RNNs and CNNs for time series, sequence and forecasting models.\n",
    "\n",
    "* [LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM): Long Short Term Memory RNN [8]\n",
    "* [GRU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU): Gated Recurrent Unit RNN. The purpose of this architecture is to solve the vanishing gradient problem. [9]\n",
    "* [Bidirectional](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional): Layer that process the sequence input in both directions using the corresponding RNN layer as a parameter (LSTM, GRU, etc.). [7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5fab14-2f10-4439-bd1e-df77eec7ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple LSTM Layer\n",
    "single_rnn_layer = tf.keras.layers.LSTM(12)\n",
    "stacked_rnn_layer = tf.keras.layers.LSTM(12, return_sequences=True)\n",
    "\n",
    "gru_layer = tf.keras.layers.GRU(12)\n",
    "\n",
    "bidirectional_lstm_layer = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(12))\n",
    "stacked_bidirectional_lstm_layer = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(12, return_sequences=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f0f47-3302-41b7-b925-c6c8c1f54e5d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 5.6. Identify when to use trailing versus centered windows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e87a9ea-595f-4935-9d82-8495f6543436",
   "metadata": {},
   "source": [
    "#### 5.7. Use TensorFlow for forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a61db-9da4-4ea6-869d-e98f841ca110",
   "metadata": {},
   "source": [
    "#### 5.8. Prepare features and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca4daa1-1991-470a-8d61-03f858774d08",
   "metadata": {},
   "source": [
    "#### 5.9. Identify and compensate for sequence bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb272cf5-b6bd-4dd9-ba33-0a09e4083707",
   "metadata": {},
   "source": [
    "#### 5.10. Adjust the learning rate dynamically in time series, sequence and prediction models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
