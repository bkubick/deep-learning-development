{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f0cad51-0fa8-4d70-a49f-12c1f0798707",
   "metadata": {},
   "source": [
    "# Transfer Learning - Part 2\n",
    "## Fine Tuning\n",
    "\n",
    "A very powerful technique in Deep Learning is the use of Transfer Learning which leverages architectures of existing models trained on a similar set to the problem at hand, and build a model from that model.\n",
    "\n",
    "1. Can leverage an existing neural network architecture proven to work on problems similar to the one in hand.\n",
    "2. Can leverage a working neural network architecture which has already learned patterns on similar data to our own, then we can adapt those patterns to our own data.\n",
    "\n",
    "For this part, we are going to look at only 10% of the same food image dataset done on the convolutional neural networks notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f639c4e-fbd0-4f42-a94e-1fffa6379cde",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35853be-4f72-43fc-aaba-5fb0e5a90d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "import sys\n",
    "from typing import Tuple\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e6074-a507-4518-8fff-faf85a973fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.get_visible_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aec184-eb09-48d8-8f46-9212291bdd90",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a48143-4eb8-4ced-8199-fad55197e7d6",
   "metadata": {},
   "source": [
    "## Step-0: Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445ebcc-cb40-4d4b-b392-ec834b993278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dataset location\n",
    "data_directory = pathlib.Path('./data/food-101/10_food_classes_10_percent')\n",
    "test_directory = data_directory / 'test'\n",
    "train_directory = data_directory / 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfbe6e4-f34b-48cb-b99c-089957bb461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.image.summarize_image_directory(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc30fd96-c0e8-4df0-a5d0-86956c12f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the class names\n",
    "class_names = utils.image.get_classnames_from_directory(train_directory)\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fc19f7-ac6e-45ee-a057-bbdc82b7ed01",
   "metadata": {},
   "source": [
    "### Dataset Findings\n",
    "\n",
    "There are 10 total image classes, but instead of 750 images for each training dataset in the CNN notebook, there are only 75 for each training dataset. The test data is the same size as the test set in the CNN notebook, which will allow us for a 1-to-1 comparison against the CNN notebook model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbd75b9-492e-4dbd-9926-3ea07ec3b706",
   "metadata": {},
   "source": [
    "## Initial Pass - Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a37e9-e0d2-4f6a-a579-f4e6f635ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling values\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "\n",
    "# Loading in the data\n",
    "train_data = tf.keras.utils.image_dataset_from_directory(str(train_directory),\n",
    "                                                         image_size=(img_size, img_size),\n",
    "                                                         batch_size=batch_size,\n",
    "                                                         label_mode='categorical')\n",
    "\n",
    "test_data = tf.keras.utils.image_dataset_from_directory(str(test_directory),\n",
    "                                                        image_size=(img_size, img_size),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        label_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a17d1b-6f75-449b-859d-4ad3cef45a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc7c461-4b33-4737-9a88-742823245f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f070b6e-c4c3-455c-b5f9-f2c17b69ae59",
   "metadata": {},
   "source": [
    "#### Findings:\n",
    "\n",
    "* The data is not normalized.\n",
    "* 10 class names\n",
    "* 750 files for training and 2500 files for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50447b78-b2aa-4061-9923-d3793cd9dddb",
   "metadata": {},
   "source": [
    "## Model with Functional API Rather than Sequential API\n",
    "\n",
    "The sequential api is straight forward, it runs the layers in sequential order. The functional api allows for more customizable models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdfb158-58eb-483d-bd31-fd14916edd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create base model with tf.keras.applications models (starting from an existing model)\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "\n",
    "# 2. Need to freeze the base model (underlying pretrained patterns aren't updated while training)\n",
    "base_model.trainable = False\n",
    "\n",
    "# 3. Create the input layer\n",
    "inputs = tf.keras.layers.Input(shape=(img_size, img_size, 3), name='InputLayer')\n",
    "\n",
    "# 4. If using a model like ResNet50V2, you will need to normalize inputs.\n",
    "#    Normalization layer (Not required for the EfficientNets because it is built into that model already)\n",
    "# rescale = tf.keras.layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "# 5. Pass inputs into base_model\n",
    "x = base_model(inputs)\n",
    "\n",
    "# 6. Average pool the outputs of the base model (aggregate all the most important information).\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(name='GlobalAveragePoolingLayer')(x)\n",
    "\n",
    "# 7. Create the output layer\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax', name='OutputLayer')(x)\n",
    "\n",
    "# 8. Create model with the given inputs and outputs\n",
    "efficient_net_model_0 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# 9. Compile Model\n",
    "efficient_net_model_0.compile(loss='categorical_crossentropy',\n",
    "                            optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "                            metrics=['accuracy'])\n",
    "\n",
    "# 10. Fit the model\n",
    "efficient_net_model_0_history = efficient_net_model_0.fit(\n",
    "    train_data,\n",
    "    epochs=5,\n",
    "    steps_per_epoch=len(train_data),\n",
    "    validation_data=test_data,\n",
    "    validation_steps=int(0.25 * len(test_data)),\n",
    "    callbacks=[\n",
    "      utils.image.create_tensorboard_callback('logs/transfer_learning', '10_percent_efficient_net_model_0')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0d1d61-7e30-4d54-84a3-7c10bb60413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab694b-36fc-4a7a-aa84-626b51cf810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_net_model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb05c7-2f2d-48c7-9a64-83d5182ecc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.visualize.visualize_model(efficient_net_model_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e6ae32-8e9f-40a6-8d58-667845d7afdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_history(efficient_net_model_0_history, metric='loss')\n",
    "utils.plot.plot_history(efficient_net_model_0_history, metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11b18d6-fda3-48e6-b97c-61550d79a5d0",
   "metadata": {},
   "source": [
    "## Feature Vector from Trained Model\n",
    "\n",
    "Let's demonstrate the Global Average Pooling 2D Layer...\n",
    "\n",
    "We have a tensor after our model goes through `base_model` of shape (None, 7, 7, 1280), but when it passes through the GlobalAveragePooling2D layer, it turns into (None, 1280). This vector, (None, 1280), is our feature vector.\n",
    "\n",
    "GlobalAveragePooling2D will transform a 4D Tensor into a 2D tensor. Al this does is grabs the mean of the middle two axes to condense the information into a lower dimensional feature vector.\n",
    "\n",
    "### What is a feature vector?\n",
    "A feature vector is a learned representation of the input data (a compressed form of the input data based on how the model see's it). For instance, the GlobalAveragePooling2D feature vectorization will grab the mean across dimensions, to condense all the information in those dimensions into a lower dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd444436-a423-4503-991b-21d7ce38a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# input shape\n",
    "input_shape = (1, 4, 4, 3)\n",
    "\n",
    "# Create random tensor\n",
    "input_tensor = tf.random.normal(input_shape)\n",
    "print(f'Input Tensor: {input_tensor}')\n",
    "\n",
    "# Global average pooling layer\n",
    "global_average_pooled_tensor = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
    "print(f'Global Average Pooled Tensor: {global_average_pooled_tensor}')\n",
    "\n",
    "print(f'Input Shape: {input_shape}')\n",
    "print(f'Global Average 2D Shape: {global_average_pooled_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bfc945-44bc-4ed3-a876-615a45326c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets replicate the GlobalAveragePool2D\n",
    "# Grabs the mean of the middle two axes to condense the information into a lower dimensional feature vector.\n",
    "tf.reduce_mean(input_tensor, axis=[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1e6b55-b7d3-4590-9adc-0d00c785c2c2",
   "metadata": {},
   "source": [
    "# Transfer Learning Experiments\n",
    "\n",
    "We've seen the incredible results that transfer learning can get with only 10% of the training data, but how will it do with only 1% of the training data?\n",
    "\n",
    "NOTE: Throughout all experiments, the same test dataset will be used to evaluate our model. This ensures consistancy accross validation metrics.\n",
    "\n",
    "1. Model-1: Use feature extraction transfer learning with 1% of the training data with data augmentation.\n",
    "2. Model-2: Use feature extraction transfer learning with 10% of the training data with data augmentation.\n",
    "3. Model-3: Use fine tuning transfer learning on 10% of the training data with data augmentation.\n",
    "4. Model-4: Use fine tuning transfer learning on 100% of the training data with data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1d9e8-2363-4b2d-a2cc-451b7481dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb386b4-7015-4c8f-87d7-22c4195b08c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dataset location\n",
    "all_data_directory = pathlib.Path('./data/food-101/10_food_classes_all_data')\n",
    "all_train_directory = all_data_directory / 'train'\n",
    "\n",
    "ten_percent_data_directory = pathlib.Path('./data/food-101/10_food_classes_10_percent')\n",
    "ten_percent_train_directory = ten_percent_data_directory / 'train'\n",
    "\n",
    "one_percent_data_directory = pathlib.Path('./data/food-101/10_food_classes_1_percent')\n",
    "one_percent_train_directory = one_percent_data_directory / 'train'\n",
    "\n",
    "test_directory = all_data_directory / 'test'  # Same for both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47d1e87-9cf9-47de-af66-fc5968bea9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.image.summarize_image_directory(all_data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273da4a2-5af2-4670-a82d-b97f3e5d3452",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.image.summarize_image_directory(ten_percent_data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ddb14-3cb1-47c2-8ca8-5f1f514e9f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.image.summarize_image_directory(one_percent_data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eb3dba-7b17-4fd2-94f7-30ea3f54889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling values\n",
    "img_size = 224\n",
    "\n",
    "# Loading in the data\n",
    "\n",
    "one_percent_train_data = tf.keras.utils.image_dataset_from_directory(str(one_percent_train_directory),\n",
    "                                                                     image_size=(img_size, img_size),\n",
    "                                                                     label_mode='categorical')\n",
    "\n",
    "ten_percent_train_data = tf.keras.utils.image_dataset_from_directory(str(ten_percent_train_directory),\n",
    "                                                                     image_size=(img_size, img_size),\n",
    "                                                                     label_mode='categorical')\n",
    "\n",
    "all_train_data = tf.keras.utils.image_dataset_from_directory(str(all_train_directory),\n",
    "                                                             image_size=(img_size, img_size),\n",
    "                                                             label_mode='categorical')\n",
    "\n",
    "test_data = tf.keras.utils.image_dataset_from_directory(str(test_directory),\n",
    "                                                        image_size=(img_size, img_size),\n",
    "                                                        label_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c3373-315f-4193-b262-f241c82f6092",
   "metadata": {},
   "source": [
    "### Augmenting data as a layer in the data model\n",
    "\n",
    "Preprocessing and augmenting data can be done as a layer in the model.\n",
    "\n",
    "Benefits:\n",
    "* Data augmentation is done on the GPU instead of the CPU\n",
    "* Image data augmentation is only done on the training data, so we can still export our model and use it elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf1a7a-c9b1-412b-a565-73eb927a0b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmenting data as a layer in the data model\n",
    "# \n",
    "data_augmentation =  tf.keras.models.Sequential([\n",
    "    preprocessing.RandomFlip('horizontal'),\n",
    "    preprocessing.RandomRotation(0.2),\n",
    "    preprocessing.RandomZoom(0.2),\n",
    "    preprocessing.RandomHeight(0.2),\n",
    "    preprocessing.RandomWidth(0.2),\n",
    "    # preprocessing.Rescale(1./255), Not required for the resnet transfer learning as it is already built in\n",
    "], name='DataAugmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595c1473-2936-4ac4-b3eb-d6c84ed21f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize our data augmentation code\n",
    "# View random image and augment it through the data augmentation layer, and print view and after\n",
    "target_class = random.choice(one_percent_train_data.class_names)\n",
    "target_dir = str(one_percent_train_directory / target_class)\n",
    "\n",
    "random_image = random.choice(os.listdir(target_dir))\n",
    "random_image_path = f'{target_dir}/{random_image}'\n",
    "\n",
    "img = mpimg.imread(random_image_path)\n",
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.title(f'Original Random Image Class: {target_class}')\n",
    "plt.axis(False)\n",
    "\n",
    "augmented_img = data_augmentation(img, training=True)\n",
    "plt.figure()\n",
    "plt.imshow(augmented_img/255)  # NOTE: The augmented_img are not normalized so need to normalize it\n",
    "plt.title(f'Augmented Random Image Class: {target_class}')\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e232dd8f-a17e-471f-8099-ee6113015140",
   "metadata": {},
   "source": [
    "## Model-1: Feature Extraction Transfer Learning with 1% of Training Data with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbfa5c9-6348-4461-9f2e-2e5ed6490e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Input Shape and BaseModel\n",
    "input_shape = (img_size, img_size, 3)\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "# InputLayer\n",
    "input_layer = layers.Input(shape=input_shape, name='InputLayer')\n",
    "\n",
    "# Augment Data Layer\n",
    "x = data_augmentation(input_layer)\n",
    "\n",
    "# Efficient Net Layer\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# Pool the output\n",
    "x = layers.GlobalAveragePooling2D(name='GlobalAveragePoolingLayer')(x)\n",
    "\n",
    "# Output Layer\n",
    "output_layer = layers.Dense(10, activation='softmax', name='OutputLayer')(x)\n",
    "\n",
    "# Create Model\n",
    "model_1 = tf.keras.models.Model(input_layer, output_layer)\n",
    "\n",
    "# Compile Model\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit Model\n",
    "history_1 = model_1.fit(\n",
    "    one_percent_train_data,\n",
    "    epochs=5,\n",
    "    steps_per_epoch=len(one_percent_train_data),\n",
    "    validation_data=test_data,\n",
    "    validation_steps=int(0.25 * len(test_data)),\n",
    "    callbacks=[\n",
    "      utils.image.create_tensorboard_callback('logs/transfer_learning', '1_percent_data_aug_efficient_net_model_0')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb76df8-47d2-4593-92bb-aa0616245066",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9db1c2-25ca-4dc4-b3d2-6250a3ff95e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_evaluation = model_1.evaluate(test_data)\n",
    "model_1_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa83b529-4616-41ac-ac4f-ccb92052c0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.visualize.visualize_model(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde218c-a8be-4535-8e0d-a84f46550b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_history(history_1, metric='loss')\n",
    "utils.plot.plot_history(history_1, metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c66ca2-d474-476e-b47f-3b90034b2abc",
   "metadata": {},
   "source": [
    "## Model-2: Feature Extraction Transfer Learning with 10% of Training Data with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de5f20-37f3-42ae-a2aa-8080141a0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Input Shape and BaseModel\n",
    "input_shape = (img_size, img_size, 3)\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "# InputLayer\n",
    "input_layer = layers.Input(shape=input_shape, name='InputLayer')\n",
    "\n",
    "# Augmentation Data Layer\n",
    "x = data_augmentation(input_layer)\n",
    "\n",
    "# Efficient Net Layer\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# Pool the output\n",
    "x = layers.GlobalAveragePooling2D(name='GlobalAveragePoolingLayer')(x)\n",
    "\n",
    "# Output Layer\n",
    "output_layer = layers.Dense(10, activation='softmax', name='OutputLayer')(x)\n",
    "\n",
    "# Create Model\n",
    "model_2 = tf.keras.models.Model(input_layer, output_layer)\n",
    "\n",
    "# Compile Model\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Fit Model (Using a model checkpoint callback to save weights during training)\n",
    "checkpoint_path = 'checkpoints/ten_percent_model_weights/checkpoint.ckpt'\n",
    "model_weight_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch',\n",
    "    verbose=1)\n",
    "\n",
    "history_2 = model_2.fit(\n",
    "    ten_percent_train_data,\n",
    "    epochs=5,\n",
    "    steps_per_epoch=len(ten_percent_train_data),\n",
    "    validation_data=test_data,\n",
    "    validation_steps=int(0.25 * len(test_data)),\n",
    "    callbacks=[\n",
    "        model_weight_checkpoint_callback,\n",
    "        utils.image.create_tensorboard_callback('logs/transfer_learning', '10_percent_data_aug_efficient_net_model_2')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6699ac-314c-4772-b397-2f849ae19143",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc825086-40b2-44a1-8cc1-3271b3d3cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_evaluation = model_2.evaluate(test_data)\n",
    "model_2_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce561b3-458b-4e01-ac51-dcaff5ea50a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_history(history_2, metric='loss')\n",
    "utils.plot.plot_history(history_2, metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcba702-2cd7-4ea2-a386-ebf168d01a5f",
   "metadata": {},
   "source": [
    "## Model-3: Fine Tuning Transfer Learning with 10% of Training Data with Data Augmentation\n",
    "\n",
    "**NOTE**: Fine tuning usually works best *after* training a feature extraction model for a few epochs with large amounts of custom data.\n",
    "\n",
    "For this model, the only thing that changes between model-2 and model-3 is that we are going to make the last 10 layers in the efficientnet model trainable. Per the note above, we need to start from a model with already trained output variables. To do this, we are going to use the already trained model-2, epoch 5 as a starting point, and train an additional 5 epochs with the last 10 layers of the efficientnet model being trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237be520-dcab-40b5-94b5-763550d03567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start with model 2 and look at each layer\n",
    "for layer in model_2.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6413662-fa4d-4b1e-8865-84483564496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many trainable variables are in base model\n",
    "print('Total Trainable Variables: ', len(model_2.layers[2].trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff5920-14a0-40cc-aab5-f46e5acb641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting from model_2 to \n",
    "# Create Model\n",
    "# model_3 = tf.keras.models.clone_model(model_2)\n",
    "\n",
    "# Setting last 10 layers in base_model to True\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile Model\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ab1c9-342b-4ae0-b513-9d820f9e9e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Trainable Variables: ', len(model_2.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fded378-fe9d-42aa-a3f7-2d5ff81a9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial epochs\n",
    "initial_epochs = 5\n",
    "\n",
    "# Fit Model\n",
    "history_3 = model_2.fit(\n",
    "    ten_percent_train_data,\n",
    "    epochs=initial_epochs + 5,\n",
    "    initial_epoch=history_2.epoch[-1],\n",
    "    steps_per_epoch=len(ten_percent_train_data),\n",
    "    validation_data=test_data,\n",
    "    validation_steps=int(0.25 * len(test_data)),\n",
    "    callbacks=[\n",
    "        utils.image.create_tensorboard_callback('logs/transfer_learning', '10_percent_fine_tuning_data_aug_efficient_net')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d8697-fd1b-4a0c-9b1f-2c921d254989",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_evaluation = model_2.evaluate(test_data)\n",
    "model_3_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12f63f-0fab-4899-bd68-ef85dc7fbe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_history(history_3, metric='loss')\n",
    "utils.plot.plot_history(history_3, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69d28d-6360-4594-9e89-99311c0860b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_histories(original_history, new_history, initial_epoch):\n",
    "    total_acc = original_history.history['accuracy'] + new_history.history['accuracy']\n",
    "    total_loss = original_history.history['loss'] + new_history.history['loss']\n",
    "    total_val_acc = original_history.history['val_accuracy'] + new_history.history['val_accuracy']\n",
    "    total_val_loss = original_history.history['val_loss'] + new_history.history['val_loss']\n",
    "\n",
    "    # Loss Plots\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(total_loss, label='Training Loss')\n",
    "    plt.plot(total_val_loss, label='Validation Accuracy')\n",
    "    plt.plot([initial_epoch, initial_epoch], plt.ylim(), label='Start Fine Tuning')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    # Accuracy Plots\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(total_acc, label='Training Accuracy')\n",
    "    plt.plot(total_val_acc, label='Validation Accuracy')\n",
    "    plt.plot([initial_epoch, initial_epoch], plt.ylim(), label='Start Fine Tuning')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1c5872-13d4-4e20-9748-091718dba65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_histories(history_2, history_3, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0bc7dd-339b-4eb2-b3e5-c9a7d65a14fe",
   "metadata": {},
   "source": [
    "## Model-4: Fine Tuning Transfer Learning with 100% of Training Data with Data Augmentation\n",
    "\n",
    "**NOTE**: Fine tuning usually works best *after* training a feature extraction model for a few epochs with large amounts of custom data.\n",
    "\n",
    "For this model, the only thing that changes between model-2 and model-4 is that we are going to make the last 10 layers in the efficientnet model trainable. Per the note above, we need to start from a model with already trained output variables. To do this, we are going to use the already trained model-2, epoch 5 as a starting point, and train an additional 5 epochs with the last 10 layers of the efficientnet model being trainable.\n",
    "\n",
    "To begin this, I need to revert model-2 back to the pre model-3 checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5415f5-5ac0-40ed-be3b-d0e784cb247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going to start by reverting model 2 to the pre model-3 state in order to train model-4\n",
    "model_2.load_weights(checkpoint_path)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b655fd6-2f0b-4b8c-a426-51231471fe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a47c17-3abf-426c-8625-1da4102fa2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the loss and accuracy match the val loss and val acc in the plots at epoch 5 above.\n",
    "model_2_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549916e-6efc-46f9-b83d-4b075a9ef18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting from model_2\n",
    "\n",
    "# Setting last 10 layers in base_model to True\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile Model\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d77a18-4bbc-4667-83bb-651ee4fb6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Trainable Variables: ', len(model_2.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aa0b2e-38b9-4224-bbb7-60463538f207",
   "metadata": {},
   "source": [
    "### !!!! NOTE !!!!\n",
    "\n",
    "The model-4 fit below takes upwards of an hour to run on my local device which letting sit does not work because jupyter notebook times out.\n",
    "\n",
    "**TODO**: Move model 4 to a python script to run via shell and save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a4fe41-55b5-4e29-82b1-dfa009aa1d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial epochs\n",
    "initial_epochs = 5\n",
    "\n",
    "# Fit Model\n",
    "history_4 = model_2.fit(\n",
    "    all_train_data,\n",
    "    epochs=initial_epochs + 5,\n",
    "    initial_epoch=history_2.epoch[-1],\n",
    "    steps_per_epoch=len(all_train_data),\n",
    "    validation_data=test_data,\n",
    "    validation_steps=int(0.25 * len(test_data)),\n",
    "    callbacks=[\n",
    "        utils.image.create_tensorboard_callback('logs/transfer_learning', 'all_data_fine_tuning_data_aug_efficient_net')\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
