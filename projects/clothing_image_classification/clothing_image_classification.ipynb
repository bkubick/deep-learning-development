{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac481715",
   "metadata": {},
   "source": [
    "# Multiclass Classification - Clothing Type Classification\n",
    "\n",
    "To put everything learned from the classification problems together, I am going to use an actual dataset to cover Multi-class classification. Multiclass classification problems are when there are more than two classes as an option (two classes is binary classification).\n",
    "\n",
    "For this example, I am classifying images of fashion, we're going to build a neural network to classify images of different items of clothing.\n",
    "\n",
    "* https://www.tensorflow.org/datasets/catalog/fashion_mnist\n",
    "* https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aec6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a162d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data has already been split\n",
    "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Create a small list so we can index onto our training labels so they're human readable\n",
    "# Grabbed from dataset github\n",
    "class_names = [\n",
    "    'T-shirt/top',\n",
    "    'Trouser',\n",
    "    'Pullover',\n",
    "    'Dress',\n",
    "    'Coat',\n",
    "    'Sandal',\n",
    "    'Shirt',\n",
    "    'Sneaker',\n",
    "    'Bag',\n",
    "    'Ankle boot',\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "583f3150",
   "metadata": {},
   "source": [
    "## Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d69bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at a single X value\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a4474",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c1b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0].shape, train_data.dtype, train_labels[0].shape, train_labels[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e718ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at some images\n",
    "utils.plot.plot_images([0, 1, 2, 3], train_data, train_labels, class_names, black_and_white=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b3a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_image(35, train_data, train_labels, class_names, black_and_white=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc08ef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a handful of images\n",
    "indexes = [random.randint(0, len(train_data)) for i in range(4)]\n",
    "utils.plot.plot_images(indexes, train_data, train_labels, class_names, black_and_white=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf2f5e44",
   "metadata": {},
   "source": [
    "## Building Multiclass Classification Model\n",
    "\n",
    "* Input shape = 28 x 28\n",
    "* Output shape = 10\n",
    "* Loss function = CategoricalCrossentropy (if one-hot encoded) or SparseCategoricalCrossentropy (if integers)\n",
    "* Output activation = SoftMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5020d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to rename my data to be more consistant with other notebooks I've done\n",
    "X_train, y_train = train_data, train_labels\n",
    "X_test, y_test = test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b62f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing my data\n",
    "X_train_norm = X_train / X_train.max()\n",
    "X_test_norm = X_test / X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b93315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed to compare models nicely\n",
    "tf.random.set_seed(27)\n",
    "\n",
    "# 1. Create Model\n",
    "# NOTE: Our data needs to be flatttened into a single vector\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(4, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "model_1.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 3. Fit Model\n",
    "history_1 = model_1.fit(X_train_norm, y_train, epochs=10, validation_data=(X_test_norm, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed739bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced9de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at model\n",
    "utils.visualize.visualize_model(model_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a689b107",
   "metadata": {},
   "source": [
    "## Finding the Ideal Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76bef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerunning model_1, but going to make a learning rate scheduler to help find optimal learning rate\n",
    "\n",
    "# Setting seed to compare models nicely\n",
    "tf.random.set_seed(27)\n",
    "\n",
    "# 1. Create Model\n",
    "model_2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(4, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "model_2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(\n",
    "    utils.learning_rate.exponential_decay_callback(decay_step=20, decay_factor=10))\n",
    "\n",
    "# 3. Fit Model w/ Learning Rate Scheduler\n",
    "history_2 = model_2.fit(\n",
    "    X_train_norm,\n",
    "    y_train,\n",
    "    epochs=40,\n",
    "    validation_data=(X_test_norm, y_test),\n",
    "    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01094a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2_df = pd.DataFrame(history_2.history)\n",
    "history_2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32f578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_history(history_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327aae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss vs epoch\n",
    "# Plot learning rate versus the loss\n",
    "lrs = 1e-3 * (10 ** (tf.range(40) / 20))\n",
    "utils.plot.plot_learning_rate_versus_loss(lrs, history_2.history['loss'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d6417db",
   "metadata": {},
   "source": [
    "#### Ideal Learning Rate\n",
    "\n",
    "After looking at the plot above, is looks like our ideal learning rate is between 0.002 and 0.001, so going to use 0.002."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf3fe568",
   "metadata": {},
   "source": [
    "### Model w/ Ideal Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ede3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed to compare models nicely\n",
    "tf.random.set_seed(27)\n",
    "\n",
    "# 1. Create Model\n",
    "# NOTE: Our data needs to be flatttened into a single vector\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(4, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
    "])\n",
    "\n",
    "# 2. Compile Model\n",
    "model_3.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.002),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# 3. Fit Model\n",
    "history_3 = model_3.fit(X_train_norm, y_train, epochs=20, validation_data=(X_test_norm, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ede9466",
   "metadata": {},
   "source": [
    "### Evaluating our Multi-class Classificaiton Model\n",
    "\n",
    "To evaluate our multi-class classification model we coild:\n",
    "* Evaluate its performance using other classification metrics (such as a confusion matrix).\n",
    "* Assess some of its predictions (through visualisations).\n",
    "* Improve its results (by training it for longer or changing the architecture).\n",
    "* Save and export it for usi in an application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values from model_3\n",
    "y_pred_3 = model_3.predict(X_test_norm)\n",
    "y_pred_3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698ea822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to convert all to integers\n",
    "y_pred_3_ints = y_pred_3.argmax(axis=1)\n",
    "y_pred_3_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix.\n",
    "utils.plot.plot_confusion_matrix(y_test, y_pred_3_ints, cell_text_size=8, classes=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5ca7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting predictions of model_3\n",
    "y_pred_probabilities = model_3.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c8a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot.plot_random_image_label_and_prediction(images=X_test_norm,\n",
    "                                                  true_labels=y_test,\n",
    "                                                  pred_probabilities=y_pred_probabilities,\n",
    "                                                  class_names=class_names,\n",
    "                                                  black_and_white = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b212c955",
   "metadata": {},
   "source": [
    "## What Patterns is the Model Learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acb15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the patterns in a network by looking at the weight of the first hidden layer\n",
    "weights, biases = model_3.layers[1].get_weights()\n",
    "\n",
    "weights, weights.shape, biases, biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb8438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: the param represents the weights and biases that are trainable for each layer:\n",
    "# flatten layer: 0 (just reshapes the data from 28x28 to 784)\n",
    "# Dense (Hidden Layer 1): 3140 (784 * 4 = 3136 weights, 4 biases (one for each neuron in layer))\n",
    "# Dense (Hidden Layer 2): 20 (4 * 4 = 16 weights, 4 biases (one for each neuron in layer))\n",
    "# Dense (Output Layer): 50 (4 * 10 = 40 weights, 10 biases (one for each neuron in layer))\n",
    "model_3.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d91b8cbb",
   "metadata": {},
   "source": [
    "## Trial-4: Testing Model Weight Saving Idea\n",
    "\n",
    "Going to test a new sequential model real quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5938c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemorySequentialModel(tf.keras.models.Sequential):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
