{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8b26a2d8-01d7-4c34-8c1c-9af1e4e1fbaf",
      "metadata": {
        "id": "8b26a2d8-01d7-4c34-8c1c-9af1e4e1fbaf"
      },
      "source": [
        "# Milestone Project 2 - Skim Lit\n",
        "\n",
        "The purpose of this project is to take medical abstracts from medical research papers, and break them down into easily readable and shortened summaries of each abstract. This is based off the PubMed paper that performs the same experiment (see link below).\n",
        "\n",
        "* https://arxiv.org/abs/1710.06071"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "djFVPOIXFf1e",
      "metadata": {
        "id": "djFVPOIXFf1e"
      },
      "source": [
        "## Environment Setup\n",
        "\n",
        "Need to figure out if I'm on google colab or on local. This will determine which commands need to be ran and how to setup the CPU/GPU being used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bXRETQTKE9hh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXRETQTKE9hh",
        "outputId": "905bb75e-4a20-4207-f629-bd2d3404b301"
      },
      "outputs": [],
      "source": [
        "# Determining if on google colab\n",
        "try:\n",
        "  from google import colab\n",
        "  on_colab = True\n",
        "except Exception:\n",
        "  on_colab = False\n",
        "\n",
        "on_colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z0x14FcXFWfa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0x14FcXFWfa",
        "outputId": "ca5ee648-e2bf-492f-ce59-3bac14a38386"
      },
      "outputs": [],
      "source": [
        "if on_colab:\n",
        "  # Setting up the notebook with a GPU\n",
        "  !nvidia-smi -L\n",
        "  !pip install py-learning-toolbox@git+https://github.com/bkubick/py-learning-toolbox.git\n",
        "  !pltb_setup_project .\n",
        "  !rm -rf ./notebooks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bff0bd53-4f41-4695-a44d-9ae6b38240d8",
      "metadata": {
        "id": "bff0bd53-4f41-4695-a44d-9ae6b38240d8"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eed36c2-1cf2-4eab-b636-53d982e2ac25",
      "metadata": {
        "id": "7eed36c2-1cf2-4eab-b636-53d982e2ac25"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "import random\n",
        "import requests\n",
        "import string\n",
        "import typing\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from py_learning_toolbox import dl_toolbox\n",
        "from py_learning_toolbox import data_toolbox\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29506c39-6a14-40d2-b629-4a6737503e49",
      "metadata": {
        "id": "29506c39-6a14-40d2-b629-4a6737503e49"
      },
      "source": [
        "## Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1c87f03-570d-4f38-a66e-d1ccdd167611",
      "metadata": {
        "id": "d1c87f03-570d-4f38-a66e-d1ccdd167611"
      },
      "outputs": [],
      "source": [
        "def preprocess_pubmed_txt_data(url: str) -> typing.List[typing.Dict[str, typing.Any]]:\n",
        "    \"\"\" Preprocessing function that grabs the data from the corresponding url, then\n",
        "        prepocesses it to clean it up into a list of dictionaries with the following keys:\n",
        "\n",
        "        - abstract_id\n",
        "        - target\n",
        "        - text\n",
        "        - line_number\n",
        "        - total_lines\n",
        "\n",
        "        Args:\n",
        "            url (str): the corresponding url the data is grabbed from.\n",
        "\n",
        "        Raises:\n",
        "            AssertionError: if there is an issue with the data that there are not\n",
        "                two blank lines between abstracts.\n",
        "\n",
        "        Returns:\n",
        "            (List[Dict]): the properly structured data.\n",
        "    \"\"\"\n",
        "    raw_abstract_data = data_toolbox.read_txt_file_from_url(url, delimiter='\\n\\n')\n",
        "\n",
        "    processed_data = []\n",
        "    for abstract in raw_abstract_data:\n",
        "        if len(abstract) == 0:\n",
        "            continue\n",
        "\n",
        "        # Verify the raw abstract item represents the start of a new abstract\n",
        "        assert abstract.startswith('###')\n",
        "\n",
        "        abstract_lines = abstract.split('\\n')\n",
        "        abstract_id = abstract_lines[0][3:]  # Abstract id is the first item in the split list, and do not include `###`\n",
        "        total_lines = len(abstract_lines) - 2  # Doesn't include the abstract id line and starts from 0\n",
        "\n",
        "        for line_number, line in enumerate(abstract_lines[1:]):\n",
        "            [target, text] = line.split('\\t')\n",
        "            processed_data.append({\n",
        "                'abstract_id': abstract_id,\n",
        "                'target': target,\n",
        "                'text': text.lower(),\n",
        "                'line_number': line_number,\n",
        "                'total_lines': total_lines,\n",
        "            })\n",
        "\n",
        "    return processed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65c26d22-48f6-4c5e-b255-edcd99e45594",
      "metadata": {
        "id": "65c26d22-48f6-4c5e-b255-edcd99e45594"
      },
      "outputs": [],
      "source": [
        "def split_chars(text: str) -> str:\n",
        "    return ' '.join(list(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "250e5ffa-6efa-4e3b-985e-2c65ca84f154",
      "metadata": {
        "id": "250e5ffa-6efa-4e3b-985e-2c65ca84f154"
      },
      "outputs": [],
      "source": [
        "# Combining token and character dataset for this specific model\n",
        "def concatenate_datasets(datasets, labels) -> tf.data.Dataset:\n",
        "    concatenated_data = tf.data.Dataset.from_tensor_slices(tuple(datasets))\n",
        "    labels_data = tf.data.Dataset.from_tensor_slices(labels)\n",
        "    concatenated_dataset = tf.data.Dataset.zip((concatenated_data, labels_data))\n",
        "\n",
        "    return concatenated_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NQIsuP4GuTon",
      "metadata": {
        "id": "NQIsuP4GuTon"
      },
      "outputs": [],
      "source": [
        "def generate_results_df(results: typing.List[dl_toolbox.analysis.classification.PredictionMetrics]) -> pd.DataFrame:\n",
        "    all_results = {}\n",
        "    for model_number, prediction_results in enumerate(results):\n",
        "        all_results[f'model_{model_number}'] = dict(prediction_results)\n",
        "\n",
        "    return pd.DataFrame(all_results).transpose()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cd230bd-7b86-4a73-88e5-f71e3e042aa6",
      "metadata": {
        "id": "7cd230bd-7b86-4a73-88e5-f71e3e042aa6"
      },
      "source": [
        "## Download & Analyze Data\n",
        "\n",
        "The data used in the paper is publicly available at the github link listed below.\n",
        "\n",
        "* https://github.com/Franck-Dernoncourt/pubmed-rct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bec01442-4a87-4205-9de3-874de6556958",
      "metadata": {
        "id": "bec01442-4a87-4205-9de3-874de6556958"
      },
      "outputs": [],
      "source": [
        "\n",
        "pubmed_data_urls = {\n",
        "    'test_url_20k': 'https://raw.githubusercontent.com/Franck-Dernoncourt/pubmed-rct/master/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
        "    'dev_url_20k': 'https://raw.githubusercontent.com/Franck-Dernoncourt/pubmed-rct/master/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
        "    'train_url_20k': 'https://raw.githubusercontent.com/Franck-Dernoncourt/pubmed-rct/master/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c3e1149-208b-441d-bba6-b40b4f32af7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c3e1149-208b-441d-bba6-b40b4f32af7a",
        "outputId": "1ec38e57-b181-446b-cdc4-2f3960a651ca"
      },
      "outputs": [],
      "source": [
        "raw_train_abstracts = data_toolbox.read_txt_file_from_url(pubmed_data_urls['train_url_20k'], '\\n\\n')\n",
        "len(raw_train_abstracts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ffcafd3-82db-422f-b6dc-2b77ed51a1d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ffcafd3-82db-422f-b6dc-2b77ed51a1d6",
        "outputId": "145c9518-a543-4770-e9f0-1d965e043977"
      },
      "outputs": [],
      "source": [
        "raw_train_abstracts[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2135a632-7707-4179-a870-5437dc607208",
      "metadata": {
        "id": "2135a632-7707-4179-a870-5437dc607208"
      },
      "source": [
        "### Preprocessing Notes\n",
        "\n",
        "After looking at the data, each abstract includes an abstract id, the target section it talks about, and the actual text. To make this usable, I am going to structure it as a list of dictionaries that contain the following keys:\n",
        "\n",
        "* abstract_id\n",
        "* line_number\n",
        "* target\n",
        "* text\n",
        "* total_lines\n",
        "\n",
        "This will be done using the function, `preprocess_pubmed_txt_data`, created in the **Helpers** section of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01f145c0-750a-4787-be6d-a56d28f006c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01f145c0-750a-4787-be6d-a56d28f006c8",
        "outputId": "89c8868f-8388-42d3-cc04-92a51b13fdb0"
      },
      "outputs": [],
      "source": [
        "preprocessed_train_data = preprocess_pubmed_txt_data(pubmed_data_urls['train_url_20k'])\n",
        "preprocessed_val_data = preprocess_pubmed_txt_data(pubmed_data_urls['dev_url_20k'])\n",
        "preprocessed_test_data = preprocess_pubmed_txt_data(pubmed_data_urls['test_url_20k'])\n",
        "\n",
        "len(preprocessed_train_data), len(preprocessed_val_data), len(preprocessed_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22ba7332-d1f8-4dd7-9e69-c46c5665f13f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22ba7332-d1f8-4dd7-9e69-c46c5665f13f",
        "outputId": "54f3f9cd-1f0a-464a-f669-2076901185e8"
      },
      "outputs": [],
      "source": [
        "preprocessed_train_data[:12]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "babadc5d-296a-4d0c-8238-f17cdb244e66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "babadc5d-296a-4d0c-8238-f17cdb244e66",
        "outputId": "c2424128-c811-4b4f-e71f-09f79b9183bf"
      },
      "outputs": [],
      "source": [
        "train_df = pd.DataFrame(preprocessed_train_data)\n",
        "test_df = pd.DataFrame(preprocessed_test_data)\n",
        "val_df = pd.DataFrame(preprocessed_val_data)\n",
        "\n",
        "train_df.head(12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57c67838-1cc5-4e74-900e-bf5fb10c558c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57c67838-1cc5-4e74-900e-bf5fb10c558c",
        "outputId": "c75c4818-abe8-43c5-9e81-ea9a294de5d0"
      },
      "outputs": [],
      "source": [
        "train_df.target.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca5b275b-77cb-4ef2-af81-99fddeea6c91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "ca5b275b-77cb-4ef2-af81-99fddeea6c91",
        "outputId": "0b7bfe0f-845f-4cbc-93e8-bf9c72c45f58"
      },
      "outputs": [],
      "source": [
        "train_df.total_lines.plot.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2722d97-57b2-4ed9-ab73-fdf4489506cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2722d97-57b2-4ed9-ab73-fdf4489506cf",
        "outputId": "c169ed4c-db51-4224-f659-a9501ec97e2a"
      },
      "outputs": [],
      "source": [
        "train_sentences = train_df.text.tolist()\n",
        "test_sentences = test_df.text.tolist()\n",
        "val_sentences = val_df.text.tolist()\n",
        "\n",
        "len(train_sentences), len(test_sentences), len(val_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b91f6c7f-38d0-4b28-a0a9-4af64395705e",
      "metadata": {
        "id": "b91f6c7f-38d0-4b28-a0a9-4af64395705e"
      },
      "source": [
        "### Text to Numeric Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "839b5c45-0b20-4183-80b0-fa14edbd0f90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "839b5c45-0b20-4183-80b0-fa14edbd0f90",
        "outputId": "04bf2db3-f379-4613-ad96-2a28bfc40c0d"
      },
      "outputs": [],
      "source": [
        "# One hot encode labels\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df.target.to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df.target.to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df.target.to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b72a20-2569-472b-91d8-40fd8387a938",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4b72a20-2569-472b-91d8-40fd8387a938",
        "outputId": "69bc1352-d91e-4e5b-9fa6-822c4fe95e3f"
      },
      "outputs": [],
      "source": [
        "# Label Encode Labels\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df.target.to_numpy())\n",
        "val_labels_encoded = label_encoder.fit_transform(val_df.target.to_numpy())\n",
        "test_labels_encoded = label_encoder.fit_transform(test_df.target.to_numpy())\n",
        "\n",
        "train_labels_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38681213-00db-4087-a579-b32796de785a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38681213-00db-4087-a579-b32796de785a",
        "outputId": "b060fb85-86d0-4b5c-99a5-b9a66f90dc09"
      },
      "outputs": [],
      "source": [
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "num_classes, class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6e676ed-a7c3-484e-b52f-fe8e2a8a76bf",
      "metadata": {
        "id": "e6e676ed-a7c3-484e-b52f-fe8e2a8a76bf"
      },
      "source": [
        "#### Creating Datasets\n",
        "\n",
        "Going to setup the data to run as fast as possible using the TensorFlor tf.data API. The purpose of this is that TensorFlow has setup datasets that are used to optimize performance when training, validating, and testing by utilizing both the CPU and GPU as efficiently as they can be used.\n",
        "\n",
        "To utilize this functionality, we must create datasets that can be used when experimenting with models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0768b9bd-cd7f-4c48-9f72-70f68ca7b99a",
      "metadata": {
        "id": "0768b9bd-cd7f-4c48-9f72-70f68ca7b99a"
      },
      "source": [
        "#### Sentence Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3424493-a7d4-454d-bcd8-d6aa898e9def",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3424493-a7d4-454d-bcd8-d6aa898e9def",
        "outputId": "83d80c0f-b637-4131-85d7-79b3a2682470"
      },
      "outputs": [],
      "source": [
        "# Creating the final dataset to be used\n",
        "train_slice_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "val_slice_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_slice_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_slice_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f662fdef-6993-4a22-8e51-31732a480edd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f662fdef-6993-4a22-8e51-31732a480edd",
        "outputId": "a3afbc0c-72b8-4958-e0b5-d22bc9eed77e"
      },
      "outputs": [],
      "source": [
        "# Take TensorSliceDataset and turn into prefetch models\n",
        "train_dataset = train_slice_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_slice_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_slice_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a45100bb-3244-48ac-862e-03643e0f7b79",
      "metadata": {
        "id": "a45100bb-3244-48ac-862e-03643e0f7b79"
      },
      "source": [
        "#### Character Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86c405ca-f323-4a48-9d9a-b5249fb58ee9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86c405ca-f323-4a48-9d9a-b5249fb58ee9",
        "outputId": "f9a36130-895c-4f19-a420-e0796ca8efc3"
      },
      "outputs": [],
      "source": [
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
        "\n",
        "train_chars[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1070ff7b-948e-48bd-be50-0158b4a14f4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1070ff7b-948e-48bd-be50-0158b4a14f4d",
        "outputId": "76ff601b-c3e8-411e-fb2c-17da3c39882a"
      },
      "outputs": [],
      "source": [
        "# Creating the final dataset to be used\n",
        "train_chars_slice_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot))\n",
        "val_chars_slice_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot))\n",
        "test_chars_slice_dataset = tf.data.Dataset.from_tensor_slices((test_chars, test_labels_one_hot))\n",
        "\n",
        "train_chars_slice_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a20ef38c-7a89-489c-a6cd-a857000a3a4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a20ef38c-7a89-489c-a6cd-a857000a3a4d",
        "outputId": "eb48ad69-04c2-4a1b-c5a0-7de8dd8e26c0"
      },
      "outputs": [],
      "source": [
        "# Take TensorSliceDataset and turn into prefetch models\n",
        "train_char_dataset = train_chars_slice_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = val_chars_slice_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_char_dataset = test_chars_slice_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_char_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce7ecc61-dfef-4a0d-9813-e19241a427b1",
      "metadata": {
        "id": "ce7ecc61-dfef-4a0d-9813-e19241a427b1"
      },
      "source": [
        "## Experiments\n",
        "\n",
        "The models I am building will all be compared against Model-0 (baseline) which does not use Deep Learning, rather it uses a Naive Bayes ML model.\n",
        "\n",
        "0. Model-0 (Baseline): Naive Bayes w/ TF-IDF Encoder\n",
        "1. Model-1: Conv1D w/ Token Embeddings\n",
        "2. Model-2: TensorFlow Hub Pretrained Feature Extractor\n",
        "3. Model-3: Conv1D w/ Character Embeddings\n",
        "4. Model-4: Pretrained Token Embeddings (same as Model-2) + Character Embeddings (same as Model-3)\n",
        "5. Model-5: Pretrained Token Embeddings + Character Embeddings + Positional Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cebd2c4-a535-4393-92d1-6460e117a31a",
      "metadata": {
        "id": "7cebd2c4-a535-4393-92d1-6460e117a31a"
      },
      "source": [
        "### Preprocessing Layer Setup\n",
        "\n",
        "Many embedding layers will be reused for more than one of the experiments mentioned above. These steps will setup the layers to be used in experiments such that they can be reused for multiple models. The various layers to be made are:\n",
        "\n",
        "* `text_vectorizer` (TextVectorizer)\n",
        "* `token_embedding` (Embedding)\n",
        "* `character_vectorizer` (TextVectorizer)\n",
        "* `character_embeddings` (Embedding)\n",
        "* `positional_embeddings`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2378b569-b2b1-4a70-a23f-cc41eefddde3",
      "metadata": {
        "id": "2378b569-b2b1-4a70-a23f-cc41eefddde3"
      },
      "source": [
        "#### Token Embeddings Layers\n",
        "\n",
        "These layers consist of the `text_vectorizer` and the `embedding` layers that will be reused."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a910ee15-2ab8-4fac-8b5e-a33cddb16398",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a910ee15-2ab8-4fac-8b5e-a33cddb16398",
        "outputId": "8fd8c25b-f419-4fde-e3c6-0ccde3f6efbd"
      },
      "outputs": [],
      "source": [
        "# Find average number of tokens\n",
        "sent_lens = [len(i.split()) for i in train_sentences]\n",
        "round(sum(sent_lens) / len(train_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f0bce63-e53f-424f-b6c7-deec929af1f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f0bce63-e53f-424f-b6c7-deec929af1f1",
        "outputId": "946d5e2d-6d30-4d97-a711-cff029c045fb"
      },
      "outputs": [],
      "source": [
        "# How long of a sentence covers 95% of the examples?\n",
        "int(np.percentile(sent_lens, 95))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd924928-1b03-4c38-95be-da77c25f7d9f",
      "metadata": {
        "id": "cd924928-1b03-4c38-95be-da77c25f7d9f"
      },
      "outputs": [],
      "source": [
        "# Setup text vectorization params\n",
        "max_vocab_length = 68000  # Max words to have in our vocab\n",
        "max_length = 55  # Max length our sequence will be (95% of examples are within length of 55)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61eff4e0-0d67-4061-be97-58f0efaca78a",
      "metadata": {
        "id": "61eff4e0-0d67-4061-be97-58f0efaca78a"
      },
      "outputs": [],
      "source": [
        "# Setting up a text vectorization layer (tokenization)\n",
        "text_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "    max_tokens=max_vocab_length,  # How many words in the vocabulary\n",
        "    output_sequence_length=max_length)  # Padds (adds 0's to end of number) to make all the same length\n",
        "\n",
        "# Adapt the vectorizer to the training data\n",
        "text_vectorizer.adapt(train_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69e6a374-5607-4d4e-becb-d5dbf951829b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69e6a374-5607-4d4e-becb-d5dbf951829b",
        "outputId": "df9252a6-c8c0-4bbf-950b-c6c6adf3b796"
      },
      "outputs": [],
      "source": [
        "# Getting the words in the vocab from the training data\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5]\n",
        "least_common_5_words = words_in_vocab[-5:]\n",
        "len(words_in_vocab), top_5_words, least_common_5_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59c1e832-6e77-43a0-b031-b75ba3a2a912",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59c1e832-6e77-43a0-b031-b75ba3a2a912",
        "outputId": "404c5ac5-dae2-4038-f3a5-9ff08aa5b15f"
      },
      "outputs": [],
      "source": [
        "# Config of text vectorizer layer\n",
        "text_vectorizer.get_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bb3f265-81d0-4fca-8860-6f2e7408a81b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bb3f265-81d0-4fca-8860-6f2e7408a81b",
        "outputId": "7e678032-332e-44a4-e41f-baa88f08aceb"
      },
      "outputs": [],
      "source": [
        "# Setting up the Embedding layer\n",
        "token_embedding = tf.keras.layers.Embedding(input_dim=len(words_in_vocab),\n",
        "                                            output_dim=128,  # GPU's work well when number is divisible by 8\n",
        "                                            mask_zero=True,\n",
        "                                            name='token_embedding')\n",
        "token_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02d5e03d-104e-4602-8d0e-4c00328ebc42",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02d5e03d-104e-4602-8d0e-4c00328ebc42",
        "outputId": "3417921b-74d0-4865-abfb-750fb4afe787"
      },
      "outputs": [],
      "source": [
        "# Testing out an example sentence\n",
        "target_sentence = random.choice(train_sentences)\n",
        "\n",
        "# Looking at the steps of tokenization\n",
        "print(f'Sentence before vectorization: \\n {target_sentence}')\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f'Sentence after vectorization: \\n {vectorized_sentence}')\n",
        "embedded_sentence = token_embedding(vectorized_sentence)\n",
        "print(f'Sentence after embedding: \\n {embedded_sentence}')\n",
        "print(f'Embedded sentence shape: {embedded_sentence.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "559efdf4-dd14-4f62-9ca6-aec39390aa9c",
      "metadata": {
        "id": "559efdf4-dd14-4f62-9ca6-aec39390aa9c"
      },
      "source": [
        "#### Chracacter Embedding Layer\n",
        "\n",
        "A character level embedding layer will require tokenizing characters before creating the embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e329f482-68bc-4471-abe1-b2197c23b9bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e329f482-68bc-4471-abe1-b2197c23b9bf",
        "outputId": "c097c194-5662-49fb-878f-2fac418529f9"
      },
      "outputs": [],
      "source": [
        "# Whats the avg character length?\n",
        "chars_lens = [len(sentence) for sentence in train_sentences]\n",
        "mean_chars_lens = np.mean(chars_lens)\n",
        "\n",
        "mean_chars_lens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "730f90eb-7baa-4103-b17d-f50948ff7f01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "730f90eb-7baa-4103-b17d-f50948ff7f01",
        "outputId": "36acdb17-c580-4a65-c352-eb980f597aa8"
      },
      "outputs": [],
      "source": [
        "plt.hist(chars_lens, bins=7);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "483a4f4d-934b-4d9e-aa88-74058d42188b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "483a4f4d-934b-4d9e-aa88-74058d42188b",
        "outputId": "d4dc419b-a398-4420-a50b-288fe41fe50d"
      },
      "outputs": [],
      "source": [
        "# Find character length for 95% of sentences\n",
        "output_sequence_len = int(np.percentile(chars_lens, 95))\n",
        "output_sequence_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b00796b2-e237-49f5-85c3-0bb889f1ab64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b00796b2-e237-49f5-85c3-0bb889f1ab64",
        "outputId": "d3408e1c-cb49-40a6-a077-a55f5333bca5"
      },
      "outputs": [],
      "source": [
        "# Figuring out the total alpha-numeric characters\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "\n",
        "alphabet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "628927c4-2101-48ad-80ca-46317b0bd224",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "628927c4-2101-48ad-80ca-46317b0bd224",
        "outputId": "e1aacc0e-6edb-460a-a51c-333b61d7964b"
      },
      "outputs": [],
      "source": [
        "NUM_CHAR_TOKENS = len(alphabet) + 2  # Add 2 for space and OOV token ([UNK])\n",
        "NUM_CHAR_TOKENS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13feb3a7-a7a5-4c11-ae67-926b4089d810",
      "metadata": {
        "id": "13feb3a7-a7a5-4c11-ae67-926b4089d810"
      },
      "outputs": [],
      "source": [
        "character_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "    max_tokens=NUM_CHAR_TOKENS,\n",
        "    output_sequence_length=output_sequence_len,\n",
        "    name='char_vectorizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f71f2d6-e832-430d-be8b-2ab529a28202",
      "metadata": {
        "id": "4f71f2d6-e832-430d-be8b-2ab529a28202"
      },
      "outputs": [],
      "source": [
        "character_vectorizer.adapt(train_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fe0eafd-ed40-41db-9a60-efdda3c6a2c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fe0eafd-ed40-41db-9a60-efdda3c6a2c5",
        "outputId": "2dd864ca-3455-4fb0-f023-f73119310a1e"
      },
      "outputs": [],
      "source": [
        "char_vocab = character_vectorizer.get_vocabulary()\n",
        "print(f'Number of Different Characters: {len(char_vocab)}')\n",
        "print(f'5 Most Common Characters: {char_vocab[:5]}')\n",
        "print(f'5 Least Common Characters: {char_vocab[-5:]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e37b08-2b97-4398-9e77-9fe021e08c3c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53e37b08-2b97-4398-9e77-9fe021e08c3c",
        "outputId": "b44dfb4e-aa35-41bb-ba3b-e52f03b9ac45"
      },
      "outputs": [],
      "source": [
        "random_train_chars = random.choice(train_chars)\n",
        "\n",
        "print(f'Text:\\n{random_train_chars}')\n",
        "print(f'Length: {len(random_train_chars.split())}')\n",
        "\n",
        "vectorized_chars = character_vectorizer([random_train_chars])\n",
        "print(f'Vectorized Chars:\\n {vectorized_chars}')\n",
        "print(f'Length of Vectorized Chars: {len(vectorized_chars[0])}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc234c00-a9b1-493d-bbdf-e6010080a913",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc234c00-a9b1-493d-bbdf-e6010080a913",
        "outputId": "697da227-b345-406a-98d2-696c0b7aefc4"
      },
      "outputs": [],
      "source": [
        "character_embedding = tf.keras.layers.Embedding(input_dim=len(char_vocab),\n",
        "                                                output_dim=25,\n",
        "                                                mask_zero=True,\n",
        "                                                name='character_embedding')\n",
        "character_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2c46491-b6eb-4d95-93a4-922072241e67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2c46491-b6eb-4d95-93a4-922072241e67",
        "outputId": "8e484bfa-6e01-46e0-b104-e7a0d6f24237"
      },
      "outputs": [],
      "source": [
        "# Testing out an example sentence\n",
        "target_chars = random.choice(train_chars)\n",
        "\n",
        "# Looking at the steps of tokenization\n",
        "print(f'Chars before vectorization: \\n {target_chars}')\n",
        "\n",
        "vectorized_chars = character_vectorizer([target_chars])\n",
        "print(f'Chars after vectorization: \\n {vectorized_chars}')\n",
        "embedded_chars = character_embedding(vectorized_chars)\n",
        "print(f'Chars after embedding: \\n {embedded_chars}')\n",
        "print(f'Embedded chars shape: {embedded_chars.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zBFmc2TUP8R8",
      "metadata": {
        "id": "zBFmc2TUP8R8"
      },
      "source": [
        "#### Positional Embedding Layer\n",
        "\n",
        "A positional embedding layer will look at the position of each sentence within the abstract."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "saN8DfzTQIwO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saN8DfzTQIwO",
        "outputId": "975d7acb-103a-4574-ddad-f4dde8f44c33"
      },
      "outputs": [],
      "source": [
        "train_df['line_number'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t4k5pyxhQRAk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "t4k5pyxhQRAk",
        "outputId": "b283231f-0114-42b2-ff55-5408c7c66e66"
      },
      "outputs": [],
      "source": [
        "train_df['line_number'].plot.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MdnLKeVERHfP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdnLKeVERHfP",
        "outputId": "7ac0fb19-fc4a-4682-cd4a-b42178adabcd"
      },
      "outputs": [],
      "source": [
        "# See what number of lines covers 98% of the samples\n",
        "max_lines = int(np.percentile(train_df['line_number'].to_numpy(), 98))\n",
        "max_lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V5AY4_6VQiTV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5AY4_6VQiTV",
        "outputId": "8d5f3399-7459-416d-ea2a-212b5b8b8eca"
      },
      "outputs": [],
      "source": [
        "# Encoding line_number tensors\n",
        "train_line_numbers_one_hot = tf.one_hot(train_df['line_number'].to_numpy(), depth=max_lines)\n",
        "val_line_numbers_one_hot = tf.one_hot(val_df['line_number'].to_numpy(), depth=max_lines)\n",
        "test_line_numbers_one_hot = tf.one_hot(test_df['line_number'].to_numpy(), depth=max_lines)\n",
        "\n",
        "train_line_numbers_one_hot[:15], train_line_numbers_one_hot.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RKN6lXuKWzTr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKN6lXuKWzTr",
        "outputId": "68b2b62a-c4cb-43f2-f11f-d8e6936ae19d"
      },
      "outputs": [],
      "source": [
        "train_line_number_sliced_dataset = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot, train_labels_one_hot))\n",
        "train_line_number_dataset = train_line_number_sliced_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_line_number_sliced_dataset = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot, val_labels_one_hot))\n",
        "val_line_number_dataset = val_line_number_sliced_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_line_number_sliced_dataset = tf.data.Dataset.from_tensor_slices((test_line_numbers_one_hot, test_labels_one_hot))\n",
        "test_line_number_dataset = test_line_number_sliced_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_line_number_dataset, val_line_number_dataset, test_line_number_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YwWC5UuIRahA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwWC5UuIRahA",
        "outputId": "ac0c87f2-e5e1-4813-9758-10196e8eafa8"
      },
      "outputs": [],
      "source": [
        "train_df['total_lines'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ihIon4PHSCi8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ihIon4PHSCi8",
        "outputId": "e8aeb715-38a6-4610-f881-6170b757db97"
      },
      "outputs": [],
      "source": [
        "train_df['total_lines'].plot.hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xJsXkZzaSHQN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJsXkZzaSHQN",
        "outputId": "f6d38fa6-d6d9-494c-d739-5e816e9e63a4"
      },
      "outputs": [],
      "source": [
        "max_total_lines = int(np.percentile(train_df['total_lines'], 98))\n",
        "max_total_lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bwkWa7qeSQwk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwkWa7qeSQwk",
        "outputId": "0463199f-cf71-428e-99ba-127dddc7d2ad"
      },
      "outputs": [],
      "source": [
        "# Encoding line_number tensors\n",
        "train_total_lines_one_hot = tf.one_hot(train_df['total_lines'].to_numpy(), depth=max_total_lines)\n",
        "val_total_lines_one_hot = tf.one_hot(val_df['total_lines'].to_numpy(), depth=max_total_lines)\n",
        "test_total_lines_one_hot = tf.one_hot(test_df['total_lines'].to_numpy(), depth=max_total_lines)\n",
        "\n",
        "train_total_lines_one_hot[:15], train_total_lines_one_hot.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XOh6xOtbXBIi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOh6xOtbXBIi",
        "outputId": "dd930d92-9dd3-440a-de0b-105b90add1f2"
      },
      "outputs": [],
      "source": [
        "# Creating total lines datasets\n",
        "train_total_lines_sliced_dataset = tf.data.Dataset.from_tensor_slices((train_total_lines_one_hot, train_labels_one_hot))\n",
        "train_total_lines_dataset = train_total_lines_sliced_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_total_lines_sliced_dataset = tf.data.Dataset.from_tensor_slices((val_total_lines_one_hot, val_labels_one_hot))\n",
        "val_total_lines_dataset = val_total_lines_sliced_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_total_lines_sliced_dataset = tf.data.Dataset.from_tensor_slices((test_total_lines_one_hot, test_labels_one_hot))\n",
        "test_total_lines_dataset = test_total_lines_sliced_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_total_lines_dataset, val_total_lines_dataset, test_total_lines_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c597747-5831-4275-8b43-cb7b5139d5ef",
      "metadata": {
        "id": "5c597747-5831-4275-8b43-cb7b5139d5ef"
      },
      "source": [
        "### Model-0 (Baseline):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3465fea4-e77e-4e82-86ea-f523a08167b0",
      "metadata": {
        "id": "3465fea4-e77e-4e82-86ea-f523a08167b0"
      },
      "outputs": [],
      "source": [
        "model_0 = Pipeline([\n",
        "    ('tf-idf', TfidfVectorizer()),\n",
        "    ('clf', MultinomialNB()),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b7af4f9-bb05-4386-b969-963e18658900",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4b7af4f9-bb05-4386-b969-963e18658900",
        "outputId": "47fc87b3-330e-44c3-cff7-c139ef885d4b"
      },
      "outputs": [],
      "source": [
        "model_0.fit(X=train_sentences, y=train_labels_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39f9444d-17f0-4c23-9140-1657fa875099",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39f9444d-17f0-4c23-9140-1657fa875099",
        "outputId": "8ac88d1f-95d7-4059-ce39-5bfca2ae99ce"
      },
      "outputs": [],
      "source": [
        "model_0.score(X=val_sentences, y=val_labels_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dfdc189-a269-44ea-99c4-417c17e29bdd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dfdc189-a269-44ea-99c4-417c17e29bdd",
        "outputId": "90d300a1-80e3-4cfb-e501-b2b2c9876bd4"
      },
      "outputs": [],
      "source": [
        "model_0_preds = model_0.predict(val_sentences)\n",
        "model_0_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2040ed9-72a4-4c7d-9b7e-da71a0590c1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2040ed9-72a4-4c7d-9b7e-da71a0590c1c",
        "outputId": "b924f6bc-26b0-4f30-fdf0-3ae522890966"
      },
      "outputs": [],
      "source": [
        "model_0_results = dl_toolbox.analysis.classification.generate_prediction_metrics(val_labels_encoded, model_0_preds)\n",
        "model_0_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e44d3f99-97bf-487f-82e4-f6f0f15f1a0d",
      "metadata": {
        "id": "e44d3f99-97bf-487f-82e4-f6f0f15f1a0d"
      },
      "source": [
        "### Model-1: Conv1D w/ Token Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd2f19e1-abbc-4da7-bb96-1b1daa3b00af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd2f19e1-abbc-4da7-bb96-1b1daa3b00af",
        "outputId": "e770bd55-4650-4e47-de6b-4d2e3579a98e"
      },
      "outputs": [],
      "source": [
        "# Build Model\n",
        "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "\n",
        "text_vectors = text_vectorizer(inputs)\n",
        "token_embeddings = token_embedding(text_vectors)\n",
        "x = tf.keras.layers.Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(token_embeddings)\n",
        "x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model_1 = tf.keras.models.Model(inputs, outputs)\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "780ae907-b4fb-4cab-92d0-b31b4bb3da11",
      "metadata": {
        "id": "780ae907-b4fb-4cab-92d0-b31b4bb3da11"
      },
      "outputs": [],
      "source": [
        "# Compile Model\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c41c6827-76d8-4cb3-b735-3d4404db5ad0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c41c6827-76d8-4cb3-b735-3d4404db5ad0",
        "outputId": "65f22c74-d990-4f4b-ce34-5bb8f151b620"
      },
      "outputs": [],
      "source": [
        "# Fit Model\n",
        "model_1_history = model_1.fit(train_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_dataset)),  # Only going to look at 10% of data to speed up experimentation\n",
        "                              epochs=3,\n",
        "                              validation_data=val_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_dataset)),  # Only going to look at 10% of data to speed up experimentation\n",
        "                              callbacks=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67e7ba57-40f6-48bf-b3f2-0e065cc9fecd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "67e7ba57-40f6-48bf-b3f2-0e065cc9fecd",
        "outputId": "3eca71d7-7feb-408e-b448-816deafe66e1"
      },
      "outputs": [],
      "source": [
        "dl_toolbox.analysis.history.plot_history(model_1_history, 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f86af11-e492-4016-92d6-84f1f9f0a01a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f86af11-e492-4016-92d6-84f1f9f0a01a",
        "outputId": "7c2ccf00-549a-4968-e31a-460c282c2308"
      },
      "outputs": [],
      "source": [
        "model_1.evaluate(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01498699-172a-4fe1-8a07-f487915f1125",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01498699-172a-4fe1-8a07-f487915f1125",
        "outputId": "118a70aa-5303-4ab2-dbfa-5a8c0cd3af2e"
      },
      "outputs": [],
      "source": [
        "model_1_pred_probs = model_1.predict(val_dataset)\n",
        "model_1_pred_probs[:10], model_1_pred_probs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6604220-3884-475c-b64c-eafa03628219",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6604220-3884-475c-b64c-eafa03628219",
        "outputId": "04ed856e-3a24-4c5c-a0f4-177e3a64dd5a"
      },
      "outputs": [],
      "source": [
        "# Get the max index\n",
        "model_1_pred = tf.argmax(model_1_pred_probs, axis=1)\n",
        "model_1_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abbe5776-4df0-40fe-a6e5-9642c70329c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abbe5776-4df0-40fe-a6e5-9642c70329c2",
        "outputId": "67b96dc3-3686-4822-a3f2-1b16c1186b96"
      },
      "outputs": [],
      "source": [
        "model_1_results = dl_toolbox.analysis.classification.generate_prediction_metrics(val_labels_encoded, model_1_pred)\n",
        "model_1_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be9c0ea8-cfc0-4814-a927-814f259411d8",
      "metadata": {
        "id": "be9c0ea8-cfc0-4814-a927-814f259411d8"
      },
      "source": [
        "### Model-2: TensorFlow Hub Pretrained Feature Extractor\n",
        "\n",
        "This model will use Transfer Learning with the `Universal Sentence Encoder` pretrained model on TensorFlow Hub (see link below). This model will not allow fine-tuning of the pretrained model.\n",
        "\n",
        "* https://tfhub.dev/google/collections/universal-sentence-encoder/1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39c457b5-3b95-46fd-bfe6-f1d16664d739",
      "metadata": {
        "id": "39c457b5-3b95-46fd-bfe6-f1d16664d739"
      },
      "outputs": [],
      "source": [
        "use_url = 'https://tfhub.dev/google/universal-sentence-encoder/4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e45c3c1c-a796-4cdf-88b8-b0a0518e975a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e45c3c1c-a796-4cdf-88b8-b0a0518e975a",
        "outputId": "9e1b6b45-0125-48c2-d5a9-762ee645b377"
      },
      "outputs": [],
      "source": [
        "# Build Model\n",
        "inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
        "pretrained_embedding = hub.KerasLayer(use_url, trainable=False, name='USE')(inputs)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(pretrained_embedding)\n",
        "outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model_2 = tf.keras.models.Model(inputs, outputs, name='Model2USE')\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "904faec1-fb67-47e0-9f72-89c0e5b8a4c4",
      "metadata": {
        "id": "904faec1-fb67-47e0-9f72-89c0e5b8a4c4"
      },
      "outputs": [],
      "source": [
        "# Compile Model\n",
        "model_2.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4634923d-e9d3-46ac-814d-889a87eceb2e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4634923d-e9d3-46ac-814d-889a87eceb2e",
        "outputId": "bea58c60-cff5-4938-d690-f3504d840deb"
      },
      "outputs": [],
      "source": [
        "# Fit Model\n",
        "model_2_history = model_2.fit(train_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_dataset)),  # Only going to look at 10% of data to speed up experimentation\n",
        "                              epochs=3,\n",
        "                              validation_data=val_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_dataset)),  # Only going to look at 10% of data to speed up experimentation\n",
        "                              callbacks=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0257a11-a579-4aba-9dc2-c0bc88c17192",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "c0257a11-a579-4aba-9dc2-c0bc88c17192",
        "outputId": "41f10b11-69f2-4c63-d5d3-bdfce0c21060"
      },
      "outputs": [],
      "source": [
        "dl_toolbox.analysis.history.plot_history(model_2_history, 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a98dd359-ea3f-4487-b1c8-beda51a821c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a98dd359-ea3f-4487-b1c8-beda51a821c1",
        "outputId": "f9ba45c9-64ff-49b6-ba00-63025933940d"
      },
      "outputs": [],
      "source": [
        "model_2_pred_probs = model_2.predict(val_dataset)\n",
        "model_2_pred_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76d905f1-6a04-468e-ab1a-c4f6f0fde93e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76d905f1-6a04-468e-ab1a-c4f6f0fde93e",
        "outputId": "9a1378b7-90bc-4a1c-9c0f-084e1f918b07"
      },
      "outputs": [],
      "source": [
        "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
        "model_2_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71562915-6de0-4653-9865-b2ede77005bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71562915-6de0-4653-9865-b2ede77005bf",
        "outputId": "a9adbb0b-f9f4-488e-ca64-4077b0164133"
      },
      "outputs": [],
      "source": [
        "model_2_results = dl_toolbox.analysis.classification.generate_prediction_metrics(val_labels_encoded, model_2_preds)\n",
        "model_2_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efd95b76-960b-43a4-bba1-248b2913ffb6",
      "metadata": {
        "id": "efd95b76-960b-43a4-bba1-248b2913ffb6"
      },
      "source": [
        "#### Findings\n",
        "\n",
        "Looks like the predictions are significantly worse than both models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70c02aee-097d-4902-9c60-28508a7c155b",
      "metadata": {
        "id": "70c02aee-097d-4902-9c60-28508a7c155b"
      },
      "source": [
        "### Model-3: Conv1D w/ Character Embeddings\n",
        "\n",
        "Character embeddings creates an embedding for each character."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42fff19d-73fb-40bb-934d-dbb92ca6eec4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42fff19d-73fb-40bb-934d-dbb92ca6eec4",
        "outputId": "6fc810b2-d710-4a80-eef1-76e160dd230b"
      },
      "outputs": [],
      "source": [
        "# Build Model\n",
        "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "\n",
        "vectorized_chars = character_vectorizer(inputs)\n",
        "embedded_chars = character_embedding(vectorized_chars)\n",
        "x = tf.keras.layers.Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(embedded_chars)\n",
        "x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model_3 = tf.keras.models.Model(inputs, outputs, name='Model3CharEmbeddingConv1D')\n",
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "805c214c-1db3-428a-847b-c00c1f9a6031",
      "metadata": {
        "id": "805c214c-1db3-428a-847b-c00c1f9a6031"
      },
      "outputs": [],
      "source": [
        "model_3.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12941feb-7e3c-441d-b656-2e40ef2f4c93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12941feb-7e3c-441d-b656-2e40ef2f4c93",
        "outputId": "36aafd95-0ab9-4484-e0cb-f82bef19b6b6"
      },
      "outputs": [],
      "source": [
        "model_3_history = model_3.fit(train_char_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_char_dataset)),  # Only going to look at 10% of data to speed up experimentation\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_char_dataset)),  # Only going to look at 10% of data to speed up experimentation\n",
        "                              callbacks=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7318437-19c4-4f0a-a6ce-0e534a90a853",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a7318437-19c4-4f0a-a6ce-0e534a90a853",
        "outputId": "7cff019f-4acb-46c1-88bb-5281301b5b2f"
      },
      "outputs": [],
      "source": [
        "dl_toolbox.analysis.history.plot_history(model_3_history, 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74d8a548-956b-449b-8b79-02a687973f50",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74d8a548-956b-449b-8b79-02a687973f50",
        "outputId": "57a33cb2-75c7-4551-f51c-f5bacb54ed79"
      },
      "outputs": [],
      "source": [
        "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
        "model_3_pred_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30a7c627-223f-435f-8cbc-8d63478010fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30a7c627-223f-435f-8cbc-8d63478010fb",
        "outputId": "e6d1d554-2adc-4544-cc39-26531cc122b8"
      },
      "outputs": [],
      "source": [
        "model_3_preds = tf.argmax(model_3_pred_probs, axis=1)\n",
        "model_3_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "774723bd-9864-49df-9bd9-848c18c65a1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "774723bd-9864-49df-9bd9-848c18c65a1b",
        "outputId": "ef82d7f6-dffb-430a-d6dd-c28f63fb2914"
      },
      "outputs": [],
      "source": [
        "model_3_results = dl_toolbox.analysis.classification.generate_prediction_metrics(val_labels_encoded, model_3_preds)\n",
        "model_3_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a2ff113-3047-45e0-8df0-df8a0100d915",
      "metadata": {
        "id": "7a2ff113-3047-45e0-8df0-df8a0100d915"
      },
      "source": [
        "### Model-4: Pretrained Token Embeddings (same as Model-2) + Character Embeddings (same as Model-3)\n",
        "\n",
        "Combining both a pretrained token embedding model with the character embedding model will concatenate the outcomes of the two models.\n",
        "\n",
        "1. Create a token level embedding model (similar to Model-2)\n",
        "2. Create a character level embedding model (similar to Model-3 with a slight modification)\n",
        "3. Combine the two models using a concatenate layer\n",
        "4. Build output layers on top of step 3 similar to the model built in the paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a36f3bde-26f3-41dc-985b-fec153cc9aca",
      "metadata": {
        "id": "a36f3bde-26f3-41dc-985b-fec153cc9aca"
      },
      "outputs": [],
      "source": [
        "use_url = 'https://tfhub.dev/google/universal-sentence-encoder/4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "612a7d9e-8916-4c6a-902f-8f170f81e38e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "612a7d9e-8916-4c6a-902f-8f170f81e38e",
        "outputId": "f9106528-69af-4db9-9cd5-ee667d458deb"
      },
      "outputs": [],
      "source": [
        "# Creating the specific datasets for the concatenated data\n",
        "train_token_character_dataset = concatenate_datasets([train_sentences, train_chars], train_labels_one_hot)\n",
        "val_token_character_dataset = concatenate_datasets([val_sentences, val_chars], val_labels_one_hot)\n",
        "test_token_character_dataset = concatenate_datasets([test_sentences, test_chars], test_labels_one_hot)\n",
        "\n",
        "train_token_character_dataset, val_token_character_dataset, test_token_character_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b422cc2f-d165-4411-8a50-89942e51e612",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b422cc2f-d165-4411-8a50-89942e51e612",
        "outputId": "be9478ed-5b71-46ae-d97b-94f46eb3a258"
      },
      "outputs": [],
      "source": [
        "# Build Model\n",
        "\n",
        "# 1. Build Pretrained Token Embeddings Model\n",
        "token_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string, name='token_input')\n",
        "\n",
        "pretrained_token_embedding = hub.KerasLayer(use_url, trainable=False, name='universal_sentence_encoder')(token_inputs)\n",
        "token_outputs = tf.keras.layers.Dense(128, activation='relu')(pretrained_token_embedding)\n",
        "\n",
        "token_embedding_model = tf.keras.models.Model(token_inputs, token_outputs)\n",
        "\n",
        "# 2. Build Character Embeddings Model (This is similar to the model in the paper, it uses Bi-LSTM as the Output Layer)\n",
        "character_inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string, name='char_input')\n",
        "\n",
        "char_vectors = character_vectorizer(character_inputs)\n",
        "char_embeddings = character_embedding(char_vectors)\n",
        "char_bi_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(24))(char_embeddings)\n",
        "\n",
        "character_embedding_model = tf.keras.models.Model(character_inputs, char_bi_lstm)\n",
        "\n",
        "# 3. Concatenating the two models\n",
        "token_char_concat = tf.keras.layers.Concatenate(name='token_char_hybrid')([token_embedding_model.output, character_embedding_model.output])\n",
        "\n",
        "# 4. Creating output layers (with dropout as done in the paper)\n",
        "combined_dropout = tf.keras.layers.Dropout(0.5)(token_char_concat)\n",
        "combined_dense = tf.keras.layers.Dense(128, activation='relu')(combined_dropout)\n",
        "final_dropout = tf.keras.layers.Dropout(0.5)(combined_dense)\n",
        "outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(final_dropout)\n",
        "\n",
        "# 5. Creating the Model\n",
        "model_4 = tf.keras.models.Model(inputs=[token_embedding_model.input, character_embedding_model.input],\n",
        "                                outputs=outputs,\n",
        "                                name='model_4_token_character_hybrid')\n",
        "model_4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8bd234f-b593-4969-966c-d5116b8fee0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        },
        "id": "f8bd234f-b593-4969-966c-d5116b8fee0f",
        "outputId": "2fd1e853-eb78-4050-e394-3c28c2ef3eed"
      },
      "outputs": [],
      "source": [
        "dl_toolbox.analysis.model.plot_model(model_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88e7f612-1c3d-4d34-8114-425a8fb56553",
      "metadata": {
        "id": "88e7f612-1c3d-4d34-8114-425a8fb56553"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model_4.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.legacy.Adam(),\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05f4586b-15c8-4b64-8bcc-c2847282875d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05f4586b-15c8-4b64-8bcc-c2847282875d",
        "outputId": "13945c0c-59b8-43b9-a600-a017ce0f934e"
      },
      "outputs": [],
      "source": [
        "# Fit Model\n",
        "model_4_history = model_4.fit(train_token_character_dataset,\n",
        "                              epochs=3,\n",
        "                              steps_per_epoch=int(0.1 * len(train_token_character_dataset)),\n",
        "                              validation_data=val_token_character_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_token_character_dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9766e62-51fc-4bc1-9900-82b97c893a75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "c9766e62-51fc-4bc1-9900-82b97c893a75",
        "outputId": "53ce1259-a603-4fe3-f892-49960d389433"
      },
      "outputs": [],
      "source": [
        "dl_toolbox.analysis.history.plot_history(model_4_history, 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fXK_N1oJLzox",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXK_N1oJLzox",
        "outputId": "23240970-c9ec-46e1-9273-56d94113c52d"
      },
      "outputs": [],
      "source": [
        "model_4_pred_probs = model_4.predict(val_token_character_dataset)\n",
        "model_4_pred_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae0ab94f-46b7-4b32-afd9-1519e8516233",
      "metadata": {
        "id": "ae0ab94f-46b7-4b32-afd9-1519e8516233"
      },
      "outputs": [],
      "source": [
        "model_4_preds = tf.argmax(model_4_pred_probs, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ExjigyIaMLlL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExjigyIaMLlL",
        "outputId": "619918c6-e5ea-48e4-8470-7f3b285e613f"
      },
      "outputs": [],
      "source": [
        "model_4_results = dl_toolbox.analysis.classification.generate_prediction_metrics(val_labels_encoded, model_4_preds)\n",
        "model_4_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "433d6b0c-4f91-4771-8777-08ca73ccf19e",
      "metadata": {
        "id": "433d6b0c-4f91-4771-8777-08ca73ccf19e"
      },
      "source": [
        "### Model-5: Pretrained Token Embeddings + Character Embeddings + Positional Embeddings\n",
        "\n",
        "This model will take into account the various embedding types used thus far, and add an additional embedding dataset that looks at the positional embeddings (location of each line within the abstract).\n",
        "\n",
        "To build this model, we will be performing the following steps:\n",
        "\n",
        "1. Create a token level model\n",
        "2. Create a character level model\n",
        "3. Create a model for the `line_number` feature\n",
        "4. Create a model for the `total_lines` feature\n",
        "5. Concatenate the outputs of token level model and character level model.\n",
        "6. Concatenate the outputs of `line_number` feature model, `total_lines` feature model, and the concatenated model from step 5.\n",
        "7. Create an output layer that accepts the output of the concatenated tribrid embedding model in step 6, and outputs the label probabilities.\n",
        "8. Create the fully combined model from all the steps.\n",
        "\n",
        "**NOTE**: Any engineered features used to train the model need to be available at test time. In our case, line numbers and total line numbers in an abstract are available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mzGOsVyqlrkt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzGOsVyqlrkt",
        "outputId": "7348e0cb-8ffa-4966-bfd7-136f00d89d9c"
      },
      "outputs": [],
      "source": [
        "# Creating the dataset for working in model 5\n",
        "# NOTE: Order of the datasets matters! It must match the order of the concatenation in the model\n",
        "train_token_character_position_dataset = concatenate_datasets(datasets=[train_line_numbers_one_hot,\n",
        "                                                                        train_total_lines_one_hot,\n",
        "                                                                        train_sentences,\n",
        "                                                                        train_chars],\n",
        "                                                              labels=train_labels_one_hot)\n",
        "val_token_character_position_dataset = concatenate_datasets(datasets=[val_line_numbers_one_hot,\n",
        "                                                                      val_total_lines_one_hot,\n",
        "                                                                      val_sentences,\n",
        "                                                                      val_chars],\n",
        "                                                            labels=val_labels_one_hot)\n",
        "test_token_character_position_dataset = concatenate_datasets(datasets=[test_line_numbers_one_hot,\n",
        "                                                                       test_total_lines_one_hot,\n",
        "                                                                       test_sentences,\n",
        "                                                                       test_chars],\n",
        "                                                             labels=test_labels_one_hot)\n",
        "\n",
        "train_token_character_position_dataset, val_token_character_position_dataset, test_token_character_position_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "maMqGRjCY9DC",
      "metadata": {
        "id": "maMqGRjCY9DC"
      },
      "outputs": [],
      "source": [
        "use_url = 'https://tfhub.dev/google/universal-sentence-encoder/4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbYSlgocNjub",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbYSlgocNjub",
        "outputId": "5f89966b-fb95-4434-ba88-f6b272bc719b"
      },
      "outputs": [],
      "source": [
        "# 1. Token Embedding Model\n",
        "token_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string, name='token_input')\n",
        "pretrained_token_embedding = hub.KerasLayer(use_url, trainable=False, name='universal_sentence_encoder')(token_inputs)\n",
        "token_outputs = tf.keras.layers.Dense(128, activation='relu')(pretrained_token_embedding)\n",
        "\n",
        "token_embedding_model = tf.keras.models.Model(token_inputs, token_outputs, name='token_embedding')\n",
        "\n",
        "# 2. Character Embedding Model\n",
        "char_inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string, name='char_input')\n",
        "char_vectors = character_vectorizer(char_inputs)\n",
        "char_embeddings = character_embedding(char_vectors)\n",
        "char_bi_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(24))(char_embeddings)\n",
        "\n",
        "character_embedding_model = tf.keras.models.Model(char_inputs, char_bi_lstm, name='character_embedding')\n",
        "\n",
        "# 3. Line Number Feature Model\n",
        "line_number_inputs = tf.keras.layers.Input(shape=(15,), dtype=tf.float32, name='line_number_input')\n",
        "line_number_outputs = tf.keras.layers.Dense(32, activation='relu')(line_number_inputs)\n",
        "\n",
        "line_number_feature_model = tf.keras.models.Model(line_number_inputs, line_number_outputs, name='line_number_feature')\n",
        "\n",
        "# 4. Total Lines Feature Model\n",
        "total_lines_inputs = tf.keras.layers.Input(shape=(20,), dtype=tf.float32, name='total_lines_input')\n",
        "total_lines_outputs = tf.keras.layers.Dense(32, activation='relu')(total_lines_inputs)\n",
        "\n",
        "total_lines_feature_model = tf.keras.models.Model(total_lines_inputs, total_lines_outputs, name='total_lines_feature')\n",
        "\n",
        "# 5. Concatenate Token and Character Level Models (including dropout layer)\n",
        "token_char_concat = tf.keras.layers.Concatenate(name='token_char_hybrid_embedding')([token_embedding_model.output, character_embedding_model.output])\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(token_char_concat)\n",
        "combined_token_char_embeddings_dropout = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "# 6. Concatenate Line Number Feature Model, Total Lines Feature Model, and Token Char Concatenated Hybrid\n",
        "tribrid_concat = tf.keras.layers.Concatenate(name='token_char_positional_embedding')([line_number_feature_model.output,\n",
        "                                                                                      total_lines_feature_model.output,\n",
        "                                                                                      combined_token_char_embeddings_dropout])\n",
        "\n",
        "# 7. Output Layers\n",
        "output_layer = tf.keras.layers.Dense(num_classes, activation='softmax', name='output_layer')(tribrid_concat)\n",
        "\n",
        "# 8. Create Model\n",
        "model_5 = tf.keras.models.Model(inputs=[line_number_feature_model.input,\n",
        "                                        total_lines_feature_model.input,\n",
        "                                        token_embedding_model.input,\n",
        "                                        character_embedding_model.input],\n",
        "                                outputs=output_layer,\n",
        "                                name='model_5_token_char_positional')\n",
        "model_5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Lic2EN-rkHkd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        },
        "id": "Lic2EN-rkHkd",
        "outputId": "10507a25-731d-412e-c94b-23b3f0fe7487"
      },
      "outputs": [],
      "source": [
        "dl_toolbox.analysis.model.plot_model(model_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5DxGgKe2mQIv",
      "metadata": {
        "id": "5DxGgKe2mQIv"
      },
      "outputs": [],
      "source": [
        "# Compile Model\n",
        "model_5.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2),  # label_smoothing helps to prevent overfitting\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99F1tcWBrH3g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99F1tcWBrH3g",
        "outputId": "b6ab2eb9-566d-4ff7-effb-3521ef1e1cd5"
      },
      "outputs": [],
      "source": [
        "model_5_history = model_5.fit(train_token_character_position_dataset,\n",
        "                              epochs=3,\n",
        "                              steps_per_epoch=int(0.1 * len(train_token_character_position_dataset)),\n",
        "                              validation_data=val_token_character_position_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_token_character_position_dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QfDFRlVJrxUd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "QfDFRlVJrxUd",
        "outputId": "1399b47a-51d5-4ed3-8865-5edd82ef066d"
      },
      "outputs": [],
      "source": [
        "dl_toolbox.analysis.history.plot_history(model_5_history, 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WkloZRRxr3fS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkloZRRxr3fS",
        "outputId": "c077c4a8-d88e-4eff-a1c8-e82818216f81"
      },
      "outputs": [],
      "source": [
        "model_5_pred_probs = model_5.predict(val_token_character_position_dataset, verbose=1)\n",
        "model_5_pred_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HKUZoKbCr9gW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKUZoKbCr9gW",
        "outputId": "4a427792-23c4-4645-cd4f-1ffe12ef0940"
      },
      "outputs": [],
      "source": [
        "model_5_preds = tf.argmax(model_5_pred_probs, axis=1)\n",
        "model_5_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6K8L_rFqsCTK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6K8L_rFqsCTK",
        "outputId": "1db3ab0e-9b17-46e2-ae64-42b5ef4dccca"
      },
      "outputs": [],
      "source": [
        "model_5_results = dl_toolbox.analysis.classification.generate_prediction_metrics(val_labels_encoded, model_5_preds)\n",
        "model_5_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "476441f1-b04c-43b6-bca9-2acfeae7bff0",
      "metadata": {
        "id": "476441f1-b04c-43b6-bca9-2acfeae7bff0"
      },
      "source": [
        "## Analysis\n",
        "\n",
        "Now that the 5 different experiments have been run, it is time to compare and analyze them."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RDXbsPkB2c0G",
      "metadata": {
        "id": "RDXbsPkB2c0G"
      },
      "source": [
        "#### Prediction Metric Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "INKJi2cct3Ua",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INKJi2cct3Ua",
        "outputId": "572b8998-c654-4c74-b06d-a9c4693fb54a"
      },
      "outputs": [],
      "source": [
        "all_results = [model_1_results, model_2_results, model_3_results, model_4_results, model_5_results]\n",
        "all_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lf2IKge-umhR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lf2IKge-umhR",
        "outputId": "90a5fbb8-27f9-4dca-e038-36398a8334e0"
      },
      "outputs": [],
      "source": [
        "all_results_df = generate_results_df(all_results)\n",
        "all_results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fec9149d-4661-4a0a-894f-04a89fc2dbd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "fec9149d-4661-4a0a-894f-04a89fc2dbd0",
        "outputId": "e2585747-af8f-4dc9-db7b-e2e826f50207"
      },
      "outputs": [],
      "source": [
        "all_results_df.plot(kind='bar', figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WfOXYU1gt8mk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "WfOXYU1gt8mk",
        "outputId": "a3e9f703-22d1-40d4-9162-a72be795068b"
      },
      "outputs": [],
      "source": [
        "all_results_df.sort_values('f1', ascending=True)['f1'].plot(kind='bar', figsize=(10, 7))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AXHTrZFNviFN",
      "metadata": {
        "id": "AXHTrZFNviFN"
      },
      "source": [
        "#### Findings\n",
        "After evaluating the model performance metrics, it looks like model_4 outperformed all other models in terms of accuracy, however the baseline model ended up being a very close second."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DzK_x9qlvybY",
      "metadata": {
        "id": "DzK_x9qlvybY"
      },
      "source": [
        "## Exporting Model\n",
        "\n",
        "Now that I have identified the top performing model, I want to export it from google colab for reuse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CAcJ4ZYexxy6",
      "metadata": {
        "id": "CAcJ4ZYexxy6"
      },
      "outputs": [],
      "source": [
        "model_5_filepath = './models/skimlit_tribrid_model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Uao-7XpnvwU8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uao-7XpnvwU8",
        "outputId": "a29ee38a-5eea-4380-d87f-1b39cf7a4b9d"
      },
      "outputs": [],
      "source": [
        "model_5.save(model_5_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n-r7ldxhwJr-",
      "metadata": {
        "id": "n-r7ldxhwJr-"
      },
      "outputs": [],
      "source": [
        "# Verifying export works as expected\n",
        "loaded_model = tf.keras.models.load_model(model_5_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WD4DocdCwjRo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD4DocdCwjRo",
        "outputId": "5e490a6a-109e-47f4-c815-ee0e678182e5"
      },
      "outputs": [],
      "source": [
        "# Verifying model_5 and loaded_model are equivalent\n",
        "loaded_pred_probs = loaded_model.predict(val_token_character_position_dataset)\n",
        "loaded_preds = tf.argmax(loaded_pred_probs, axis=1)\n",
        "loaded_model_results = dl_toolbox.analysis.classification.generate_prediction_metrics(val_labels_encoded, loaded_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sF5Zg76cw_f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF5Zg76cw_f5",
        "outputId": "2e312d54-0736-4446-bcef-c6b4a2f938b8"
      },
      "outputs": [],
      "source": [
        "loaded_model_results, model_5_results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "woJLO3lQxMf4",
      "metadata": {
        "id": "woJLO3lQxMf4"
      },
      "source": [
        "#### Findings\n",
        "\n",
        "After saving the model, then loading it back in and comparing against the original model, the performance is exactly the same. This confirms the export worked as expected."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
